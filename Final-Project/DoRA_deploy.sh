#!/bin/bash
# DoRA è®ºæ–‡å¤ç° - ä¸€é”®éƒ¨ç½²è„šæœ¬
# è®ºæ–‡: DoRA: Weight-Decomposed Low-Rank Adaptation (ICML 2024 Oral)
# é¡¹ç›®åœ°å€: https://github.com/ironhxs/LLM
# 
# ä½¿ç”¨æ–¹æ³•:
#   git clone --recurse-submodules <ä»“åº“åœ°å€>
#   cd LLM/Final-Project
#   bash DoRA_deploy.sh

set -e

echo "================================================="
echo "  DoRA è®ºæ–‡å¤ç° - è‡ªåŠ¨åŒ–éƒ¨ç½²è„šæœ¬"
echo "  é¢„è®¡æ€»æ—¶é—´: 90-120 åˆ†é’Ÿ"
echo "================================================="

# è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
cd "${SCRIPT_DIR}"

# === é˜¶æ®µ1: ç¯å¢ƒé…ç½® ===
echo -e "\n[1/4] é…ç½® Conda ç¯å¢ƒ..."
conda create -n dora_llama python=3.10 -y
source activate dora_llama || conda activate dora_llama

echo -e "\n[2/4] å®‰è£… Python ä¾èµ–..."
cd DoRA/commonsense_reasoning
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple

# === é˜¶æ®µ2: æ•°æ®å‡†å¤‡ ===
echo -e "\n[3/4] ä¸‹è½½æ•°æ®é›†..."
echo "æ­£åœ¨ä¸‹è½½ commonsense_170k è®­ç»ƒé›†..."
wget -O commonsense_170k.json https://github.com/AGI-Edgerunners/LLM-Adapters/raw/main/ft-training_set/commonsense_170k.json

mkdir -p dataset
cd dataset
echo "æ­£åœ¨ä¸‹è½½ BoolQ è¯„æµ‹é›†..."
wget https://github.com/AGI-Edgerunners/LLM-Adapters/raw/main/dataset/boolq.json
cd ..

# === é˜¶æ®µ3: æ¨¡å‹è®­ç»ƒ ===
echo -e "\n[4/4] å¯åŠ¨ DoRA è®­ç»ƒ..."
echo "é…ç½®: rank=8, alpha=16 (å¿«é€ŸéªŒè¯ç‰ˆæœ¬)"
echo "é¢„è®¡è€—æ—¶: 60-90 åˆ†é’Ÿ"
echo "-------------------------------------------------"
bash llama_7B_Dora.sh 8 16 ./result 0

# === é˜¶æ®µ4: æ¨¡å‹è¯„æµ‹ ===
echo -e "\nâœ… è®­ç»ƒå®Œæˆï¼å¼€å§‹è¯„æµ‹..."
python commonsense_evaluate.py \
  --model LLaMA-7B \
  --adapter DoRA \
  --dataset boolq \
  --base_model 'yahma/llama-7b-hf' \
  --lora_weights ./result \
  --batch_size 8

echo -e "\n================================================="
echo "  ğŸ‰ DoRA å¤ç°å®Œæˆï¼"
echo "  è®­ç»ƒæƒé‡: ./result/"
echo "  è¯„æµ‹ç»“æœ: experiment/LLaMA-7B-DoRA-boolq.json"
echo "================================================="
