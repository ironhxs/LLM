{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86762afe",
   "metadata": {},
   "source": [
    "# RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ç³»ç»Ÿå®ç°\n",
    "\n",
    "æœ¬ Notebook æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ **LangChain + FAISS + æœ¬åœ°å¤§æ¨¡å‹**æ„å»ºå®Œæ•´çš„ RAG ç³»ç»Ÿã€‚\n",
    "\n",
    "## ä»€ä¹ˆæ˜¯ RAGï¼Ÿ\n",
    "RAG (Retrieval-Augmented Generation) é€šè¿‡ä»çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼Œå°†å…¶ä½œä¸ºä¸Šä¸‹æ–‡æä¾›ç»™å¤§æ¨¡å‹ï¼Œä»è€Œç”Ÿæˆæ›´å‡†ç¡®ã€æ›´å…·é’ˆå¯¹æ€§çš„å›ç­”ã€‚\n",
    "\n",
    "## å®ç°æ­¥éª¤\n",
    "1. **åŠ è½½çŸ¥è¯†åº“æ–‡æ¡£**ï¼šä» `knowledge_base/` ç›®å½•è¯»å–æ–‡æ¡£\n",
    "2. **æ–‡æœ¬åˆ†å—**ï¼šä½¿ç”¨ RecursiveCharacterTextSplitter åˆ‡åˆ†æ–‡æ¡£\n",
    "3. **å‘é‡åŒ–**ï¼šä½¿ç”¨ HuggingFace Embeddings æ¨¡å‹ç”Ÿæˆå‘é‡\n",
    "4. **æ„å»ºç´¢å¼•**ï¼šä½¿ç”¨ FAISS åˆ›å»ºå‘é‡æ•°æ®åº“\n",
    "5. **æ£€ç´¢æµ‹è¯•**ï¼šæµ‹è¯•ç›¸ä¼¼åº¦æ£€ç´¢æ•ˆæœ\n",
    "6. **RAG é—®ç­”**ï¼šé›†æˆæœ¬åœ° Qwen æ¨¡å‹è¿›è¡Œå¢å¼ºç”Ÿæˆ\n",
    "7. **æ•ˆæœå¯¹æ¯”**ï¼šå¯¹æ¯”æœ‰/æ—  RAG çš„å›ç­”å·®å¼‚\n",
    "\n",
    "## æŠ€æœ¯æ ˆ\n",
    "- **LLM**: Qwen2.5-7B-Instruct-GPTQ-Int4\n",
    "- **Embedding**: text2vec-base-chinese\n",
    "- **å‘é‡æ•°æ®åº“**: FAISS\n",
    "- **æ¡†æ¶**: LangChain\n",
    "\n",
    "## çŸ¥è¯†åº“å†…å®¹\n",
    "æœ¬ç¤ºä¾‹åŒ…å«ä»¥ä¸‹æ•°æ®ï¼š\n",
    "\n",
    "### ğŸ“š è¯¾ç¨‹èµ„æ–™ï¼ˆ4ä¸ªæ–‡æ¡£ï¼‰\n",
    "- **course_syllabus.md**ï¼šäººå·¥æ™ºèƒ½è¯¾ç¨‹å¤§çº²ï¼ˆ7ç« å†…å®¹ã€è€ƒè¯•å®‰æ’ã€å®éªŒè®¡åˆ’ï¼‰\n",
    "- **course_faq.md**ï¼šè¯¾ç¨‹å¸¸è§é—®é¢˜ï¼ˆ25+ä¸ªQ&Aï¼Œæ¶µç›–è¯¾ç¨‹ã€ç¯å¢ƒã€RAGç­‰ï¼‰\n",
    "- **lab05_rag_guide.md**ï¼šRAGå®éªŒæŒ‡å¯¼ä¹¦ï¼ˆè¯¦ç»†å®éªŒæ­¥éª¤å’Œä»£ç ï¼‰\n",
    "- **python_ml_examples.md**ï¼šæœºå™¨å­¦ä¹ ä»£ç ç¤ºä¾‹ï¼ˆé¢„å¤„ç†ã€å›å½’ã€ç¥ç»ç½‘ç»œã€NLPï¼‰\n",
    "\n",
    "### ğŸ”’ ç§æœ‰æ•°æ®ï¼ˆ3ä¸ªç­çº§èŠ±åå†Œï¼‰\n",
    "\n",
    "- **class_roster_cs23-1.txt**ï¼šè®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-1ç­ï¼ˆ48äººï¼‰- ğŸ“Š æŸ¥è¯¢ç­çº§ç»Ÿè®¡æ•°æ®ï¼ˆç”·å¥³æ¯”ä¾‹ã€å›¢å‘˜äººæ•°ç­‰ï¼‰\n",
    "\n",
    "- **class_roster_cs23-2.txt**ï¼šè®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-2ç­ï¼ˆ49äººï¼‰- ğŸ“ æŸ¥è¯¢å­¦ç”Ÿä¿¡æ¯ï¼ˆå§“åã€å­¦å·ã€æ”¿æ²»é¢è²Œï¼‰\n",
    "\n",
    "- **class_roster_cs23-3.txt**ï¼šè®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-3ç­ï¼ˆ50äººï¼‰- ğŸ‘¥ æŸ¥è¯¢ç­çº§ç‰¹è‰²ä¿¡æ¯ï¼ˆç­å¹²éƒ¨ã€ä¼˜ç§€å­¦ç”Ÿç­‰ï¼‰\n",
    "\n",
    "- ğŸ“– æŸ¥è¯¢è¯¾ç¨‹ä¿¡æ¯ï¼ˆè€ƒè¯•æ—¶é—´ã€å®éªŒå®‰æ’ã€æŠ€æœ¯é—®é¢˜ï¼‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c569d3d6",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒå‡†å¤‡ä¸ä¾èµ–æ£€æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "805e74e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.19 | packaged by conda-forge | (main, Oct 22 2025, 22:23:22) [MSC v.1944 64 bit (AMD64)]\n",
      "å·¥ä½œç›®å½•: d:\\llm_deploy\\LLM\\LLM_DEPLOY\\notebooks\n",
      "âœ… LangChain, FAISS, SentenceTransformers å·²å®‰è£…\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"å·¥ä½œç›®å½•: {os.getcwd()}\")\n",
    "\n",
    "# æ£€æŸ¥å¿…è¦çš„åº“\n",
    "try:\n",
    "    import langchain\n",
    "    import faiss\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    print(\"âœ… LangChain, FAISS, SentenceTransformers å·²å®‰è£…\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ ç¼ºå°‘ä¾èµ–: {e}\")\n",
    "    print(\"è¯·ç¡®ä¿å·²å®‰è£… environment.yml ä¸­çš„æ‰€æœ‰ä¾èµ–\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73481a9",
   "metadata": {},
   "source": [
    "## 2. åŠ è½½çŸ¥è¯†åº“æ–‡æ¡£\n",
    "\n",
    "ä» `knowledge_base/` ç›®å½•åŠ è½½æ‰€æœ‰æ–‡æœ¬æ–‡ä»¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6efb3129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨åŠ è½½ .txt æ–‡ä»¶...\n",
      "æ‰¾åˆ° 3 ä¸ª .txt æ–‡ä»¶\n",
      "æ­£åœ¨åŠ è½½ .md æ–‡ä»¶...\n",
      "æ‰¾åˆ° 5 ä¸ª .md æ–‡ä»¶\n",
      "\n",
      "âœ… æˆåŠŸåŠ è½½ 8 ä¸ªæ–‡æ¡£\n",
      "\n",
      "æ–‡æ¡£ 1: class_roster_cs23-1.txt\n",
      "  é•¿åº¦: 2108 å­—ç¬¦\n",
      "  é¢„è§ˆ: # è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-1ç­ ç­çº§ä¿¡æ¯\n",
      "\n",
      "## å­¦æ ¡ä¿¡æ¯\n",
      "å­¦æ ¡åç§°: åˆè‚¥å·¥ä¸šå¤§å­¦å®£åŸæ ¡åŒº\n",
      "ç­çº§åç§°: è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-1ç­\n",
      "\n",
      "## ç­çº§ç‰¹è‰²\n",
      "- å­¦ä¹ å§”å‘˜: é™ˆæ€é›¨ï¼ˆå­¦å·ï¼š202301007...\n",
      "\n",
      "æ–‡æ¡£ 2: class_roster_cs23-2.txt\n",
      "  é•¿åº¦: 2197 å­—ç¬¦\n",
      "  é¢„è§ˆ: # è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-2ç­ ç­çº§ä¿¡æ¯\n",
      "\n",
      "## å­¦æ ¡ä¿¡æ¯\n",
      "å­¦æ ¡åç§°: åˆè‚¥å·¥ä¸šå¤§å­¦å®£åŸæ ¡åŒº\n",
      "ç­çº§åç§°: è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-2ç­\n",
      "\n",
      "## ç­çº§ç‰¹è‰²\n",
      "- å­¦ä¹ å§”å‘˜: æ—è¯—çªï¼ˆå­¦å·ï¼š202302007...\n",
      "\n",
      "æ–‡æ¡£ 3: class_roster_cs23-3.txt\n",
      "  é•¿åº¦: 2084 å­—ç¬¦\n",
      "  é¢„è§ˆ: # è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-3ç­ ç­çº§ä¿¡æ¯\n",
      "\n",
      "## å­¦æ ¡ä¿¡æ¯\n",
      "å­¦æ ¡åç§°: åˆè‚¥å·¥ä¸šå¤§å­¦å®£åŸæ ¡åŒº\n",
      "ç­çº§åç§°: è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-3ç­\n",
      "\n",
      "## ç­çº§ç‰¹è‰²\n",
      "- å­¦ä¹ å§”å‘˜: ææ˜è¾‰ï¼ˆå­¦å·ï¼š202303017...\n",
      "\n",
      "æ–‡æ¡£ 4: course_faq.md\n",
      "  é•¿åº¦: 5492 å­—ç¬¦\n",
      "  é¢„è§ˆ: # äººå·¥æ™ºèƒ½è¯¾ç¨‹ - å¸¸è§é—®é¢˜è§£ç­”ï¼ˆFAQï¼‰\n",
      "\n",
      "## ç›®å½•\n",
      "- [è¯¾ç¨‹ç›¸å…³](#è¯¾ç¨‹ç›¸å…³)\n",
      "- [ä½œä¸šä¸è€ƒè¯•](#ä½œä¸šä¸è€ƒè¯•)\n",
      "- [å®éªŒç¯å¢ƒ](#å®éªŒç¯å¢ƒ)\n",
      "- [Python ä¸å·¥å…·](#pyth...\n",
      "\n",
      "æ–‡æ¡£ 5: course_syllabus.md\n",
      "  é•¿åº¦: 2253 å­—ç¬¦\n",
      "  é¢„è§ˆ: # äººå·¥æ™ºèƒ½åŸç†è¯¾ç¨‹ - è¯¾ç¨‹å¤§çº²\n",
      "\n",
      "## è¯¾ç¨‹åŸºæœ¬ä¿¡æ¯\n",
      "- **è¯¾ç¨‹åç§°**: äººå·¥æ™ºèƒ½åŸç†ä¸åº”ç”¨\n",
      "- **è¯¾ç¨‹ä»£ç **: CS3301\n",
      "- **å­¦åˆ†**: 3.0\n",
      "- **æˆè¯¾æ•™å¸ˆ**: åˆ˜é›ªå—æ•™...\n",
      "\n",
      "æ–‡æ¡£ 6: lab05_rag_guide.md\n",
      "  é•¿åº¦: 7140 å­—ç¬¦\n",
      "  é¢„è§ˆ: # å®éªŒäº”ï¼šæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿæ„å»º\n",
      "\n",
      "## å®éªŒä¿¡æ¯\n",
      "- **å®éªŒåç§°**: RAG ç³»ç»Ÿæ„å»ºä¸åº”ç”¨\n",
      "- **å®éªŒå­¦æ—¶**: 4 å­¦æ—¶\n",
      "- **å®éªŒç±»å‹**: ç»¼åˆè®¾è®¡æ€§å®éªŒ\n",
      "- **é€‚ç”¨è¯¾ç¨‹...\n",
      "\n",
      "æ–‡æ¡£ 7: python_ml_examples.md\n",
      "  é•¿åº¦: 10678 å­—ç¬¦\n",
      "  é¢„è§ˆ: # Python æœºå™¨å­¦ä¹ ä»£ç ç¤ºä¾‹é›†\n",
      "\n",
      "## ç›®å½•\n",
      "1. [æ•°æ®é¢„å¤„ç†](#æ•°æ®é¢„å¤„ç†)\n",
      "2. [çº¿æ€§å›å½’](#çº¿æ€§å›å½’)\n",
      "3. [é€»è¾‘å›å½’](#é€»è¾‘å›å½’)\n",
      "4. [ç¥ç»ç½‘ç»œ](#ç¥ç»ç½‘ç»œ)\n",
      "5. [...\n",
      "\n",
      "æ–‡æ¡£ 8: README.md\n",
      "  é•¿åº¦: 776 å­—ç¬¦\n",
      "  é¢„è§ˆ: # AI è¯¾ç¨‹åŠ©æ‰‹çŸ¥è¯†åº“\n",
      "\n",
      "æœ¬ç›®å½•å­˜æ”¾ç”¨äº RAG ç³»ç»Ÿçš„çŸ¥è¯†åº“æ–‡æ¡£ã€‚\n",
      "\n",
      "## ğŸ“ æ–‡æ¡£åˆ—è¡¨\n",
      "\n",
      "### è¯¾ç¨‹ç›¸å…³\n",
      "- `course_syllabus.md` - äººå·¥æ™ºèƒ½åŸç†è¯¾ç¨‹å¤§çº²\n",
      "- `cour...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "# æ–‡æ¡£ç›®å½•\n",
    "docs_dir = '../knowledge_base'\n",
    "\n",
    "# æ–¹æ³•1ï¼šå…ˆåŠ è½½ .txt æ–‡ä»¶\n",
    "print(\"æ­£åœ¨åŠ è½½ .txt æ–‡ä»¶...\")\n",
    "txt_loader = DirectoryLoader(\n",
    "    docs_dir,\n",
    "    glob=\"**/*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={'encoding': 'utf-8'}\n",
    ")\n",
    "txt_docs = txt_loader.load()\n",
    "print(f\"æ‰¾åˆ° {len(txt_docs)} ä¸ª .txt æ–‡ä»¶\")\n",
    "\n",
    "# æ–¹æ³•2ï¼šåŠ è½½ .md æ–‡ä»¶\n",
    "print(\"æ­£åœ¨åŠ è½½ .md æ–‡ä»¶...\")\n",
    "md_loader = DirectoryLoader(\n",
    "    docs_dir,\n",
    "    glob=\"**/*.md\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={'encoding': 'utf-8'}\n",
    ")\n",
    "md_docs = md_loader.load()\n",
    "print(f\"æ‰¾åˆ° {len(md_docs)} ä¸ª .md æ–‡ä»¶\")\n",
    "\n",
    "# åˆå¹¶æ‰€æœ‰æ–‡æ¡£\n",
    "documents = txt_docs + md_docs\n",
    "\n",
    "print(f\"\\nâœ… æˆåŠŸåŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£\")\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"\\næ–‡æ¡£ {i+1}: {os.path.basename(doc.metadata['source'])}\")\n",
    "    print(f\"  é•¿åº¦: {len(doc.page_content)} å­—ç¬¦\")\n",
    "    print(f\"  é¢„è§ˆ: {doc.page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a640a12",
   "metadata": {},
   "source": [
    "## 3. æ–‡æœ¬åˆ†å—ï¼ˆChunkingï¼‰\n",
    "\n",
    "å°†é•¿æ–‡æ¡£åˆ‡åˆ†æˆè¾ƒå°çš„ç‰‡æ®µï¼Œä»¥ä¾¿æ›´ç²¾å‡†åœ°æ£€ç´¢ç›¸å…³å†…å®¹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3951e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ–‡æ¡£å·²åˆ†å‰²ä¸º 86 ä¸ªæ–‡æœ¬å—\n",
      "\n",
      "ç¤ºä¾‹æ–‡æœ¬å— 1:\n",
      "æ¥æº: class_roster_cs23-1.txt\n",
      "å†…å®¹: # è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-1ç­ ç­çº§ä¿¡æ¯\n",
      "\n",
      "## å­¦æ ¡ä¿¡æ¯\n",
      "å­¦æ ¡åç§°: åˆè‚¥å·¥ä¸šå¤§å­¦å®£åŸæ ¡åŒº\n",
      "ç­çº§åç§°: è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-1ç­\n",
      "\n",
      "## ç­çº§ç‰¹è‰²\n",
      "- å­¦ä¹ å§”å‘˜: é™ˆæ€é›¨ï¼ˆå­¦å·ï¼š2023010073ï¼‰\n",
      "- æ•°å­¦æœ€å¥½çš„å­¦ç”Ÿ: èµµå­é¾™ï¼ˆå­¦å·ï¼š2023010063ï¼‰\n",
      "- æœ€å—æ¬¢è¿çš„è€å¸ˆ: æ•°æ®ç»“æ„è¯¾ç¨‹çš„æå»ºåè€å¸ˆ\n",
      "\n",
      "## ç­çº§èŠ±åå†Œï¼ˆå…±48äººï¼‰\n",
      "\n",
      "ç¤ºä¾‹æ–‡æœ¬å— 2:\n",
      "æ¥æº: class_roster_cs23-1.txt\n",
      "å†…å®¹: ### ç”·ç”Ÿï¼ˆ40äººï¼‰\n",
      "1. åˆ˜å»ºå›½ï¼ˆ2020010071ï¼‰- å…±é’å›¢å‘˜ã€ç­é•¿ã€‘\n",
      "2. é©¬è¶…ï¼ˆ2023010055ï¼‰- å…±é’å›¢å‘˜\n",
      "3. éƒ­å³°ï¼ˆ2023010056ï¼‰- ç¾¤ä¼—\n",
      "4. è®¸æ¶›ï¼ˆ2023010057ï¼‰- å…±é’å›¢å‘˜\n",
      "5. é«˜å¼ºï¼ˆ2023010058ï¼‰- å…±é’å›¢å‘˜\n",
      "6. æ²ˆå†›ï¼ˆ2023010059ï¼‰- å…±é’å›¢å‘˜\n",
      "7. é’±ä¼Ÿï¼ˆ2023010060ï¼‰- å…±é’å›¢å‘˜\n",
      "8. å­™æ°ï¼ˆ2023010061ï¼‰- å…±é’å›¢å‘˜\n",
      "9. ææµ©ï¼ˆ2023010062ï¼‰- å…±é’å›¢å‘˜\n",
      "10. èµµå­é¾™ï¼ˆ2023010063ï¼‰- å…±é’å›¢å‘˜ã€æ•°å­¦æœ€å¼ºã€‘\n",
      "11. å‘¨ç£Šï¼ˆ2023010064ï¼‰- ç¾¤ä¼—\n",
      "12. å´å‹‡ï¼ˆ2023010065ï¼‰- å…±é’å›¢å‘˜\n",
      "13. éƒ‘å¼ºï¼ˆ2023010067ï¼‰- ç¾¤ä¼—\n",
      "14. ç‹å‡¯ï¼ˆ2023010069ï¼‰- å…±é’å›¢å‘˜\n",
      "15. å†¯æ¶›ï¼ˆ2023010070ï¼‰- å…±é’å›¢å‘˜\n",
      "16. é™ˆæ˜ï¼ˆ2023010072ï¼‰- ç¾¤ä¼—\n",
      "17. è¤šæµ©ï¼ˆ2023010074ï¼‰- å…±é’å›¢å‘˜\n",
      "18. å«é¹ï¼ˆ2023010075ï¼‰- ç¾¤ä¼—\n",
      "19. è’‹å³°ï¼ˆ2023010077ï¼‰- å…±é’å›¢å‘˜\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# åˆ›å»ºæ–‡æœ¬åˆ†å‰²å™¨\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,        # æ¯ä¸ªå—æœ€å¤§ 500 å­—ç¬¦\n",
    "    chunk_overlap=50,      # å—ä¹‹é—´é‡å  50 å­—ç¬¦ï¼ˆä¿æŒä¸Šä¸‹æ–‡è¿è´¯ï¼‰\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"ã€‚\", \"ï¼\", \"ï¼Ÿ\", \";\", \",\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# åˆ†å‰²æ–‡æ¡£\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"âœ… æ–‡æ¡£å·²åˆ†å‰²ä¸º {len(chunks)} ä¸ªæ–‡æœ¬å—\")\n",
    "print(f\"\\nç¤ºä¾‹æ–‡æœ¬å— 1:\")\n",
    "print(f\"æ¥æº: {os.path.basename(chunks[0].metadata['source'])}\")\n",
    "print(f\"å†…å®¹: {chunks[0].page_content}\")\n",
    "print(f\"\\nç¤ºä¾‹æ–‡æœ¬å— 2:\")\n",
    "print(f\"æ¥æº: {os.path.basename(chunks[1].metadata['source'])}\")\n",
    "print(f\"å†…å®¹: {chunks[1].page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20af7802",
   "metadata": {},
   "source": [
    "## 4. å‘é‡åŒ–ï¼ˆEmbeddingï¼‰\n",
    "\n",
    "ä½¿ç”¨ HuggingFace çš„ä¸­æ–‡ Embedding æ¨¡å‹å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b2a78a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU æ˜¾å­˜ä½¿ç”¨æƒ…å†µï¼š\n",
      "  å·²åˆ†é…: 5499.53 MB\n",
      "  å·²ç¼“å­˜: 5538.00 MB\n",
      "  æ€»æ˜¾å­˜: 8187.50 MB\n"
     ]
    }
   ],
   "source": [
    "# æ¸…ç† GPU æ˜¾å­˜ï¼ˆå¦‚æœä¹‹å‰æœ‰è¿è¡Œè¿‡å…¶ä»–æ¨¡å‹ï¼‰\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    # æŸ¥çœ‹å½“å‰æ˜¾å­˜ä½¿ç”¨æƒ…å†µ\n",
    "    print(f\"GPU æ˜¾å­˜ä½¿ç”¨æƒ…å†µï¼š\")\n",
    "    print(f\"  å·²åˆ†é…: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB\")\n",
    "    print(f\"  å·²ç¼“å­˜: {torch.cuda.memory_reserved(0) / 1024**2:.2f} MB\")\n",
    "    print(f\"  æ€»æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**2:.2f} MB\")\n",
    "else:\n",
    "    print(\"æœªæ£€æµ‹åˆ° GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b4327bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding æ¨¡å‹å°†ä½¿ç”¨è®¾å¤‡: cpu\n",
      "\n",
      "æ­£åœ¨ä¸‹è½½/åŠ è½½ Embedding æ¨¡å‹...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-15 22:24:06,883 - modelscope - WARNING - Repo AI-ModelScope/text2vec-base-chinese not exists on https://www.modelscope.cn, will try on alternative endpoint https://www.modelscope.ai.\n",
      "2025-12-15 22:24:08,492 - modelscope - ERROR - Repo AI-ModelScope/text2vec-base-chinese not exists on either https://www.modelscope.cn or https://www.modelscope.ai\n",
      "C:\\Users\\Iron\\AppData\\Local\\Temp\\ipykernel_42824\\1723070349.py:21: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelScope ä¸‹è½½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤è·¯å¾„: <Response [404]>\n",
      "âœ… Embedding æ¨¡å‹åŠ è½½å®Œæˆ\n",
      "\n",
      "æµ‹è¯•æ–‡æœ¬: 'è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-2ç­çš„å­¦ä¹ å§”å‘˜'\n",
      "å‘é‡ç»´åº¦: 768\n",
      "å‘é‡å‰5ä¸ªå…ƒç´ : [-0.026781510561704636, -0.03526550903916359, 0.057388756424188614, 0.023163367062807083, 0.03961726650595665]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from modelscope import snapshot_download\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Embedding æ¨¡å‹æ¯”è¾ƒå°ï¼Œå¦‚æœ GPU æ˜¾å­˜ä¸è¶³å¯ä»¥ç”¨ CPU\n",
    "# å¯¹äºå‘é‡åŒ–ä»»åŠ¡ï¼ŒCPU ä¹Ÿè¶³å¤Ÿå¿«\n",
    "device = 'cpu'  # å¼ºåˆ¶ä½¿ç”¨ CPUï¼Œé¿å…æ˜¾å­˜ä¸è¶³\n",
    "print(f\"Embedding æ¨¡å‹å°†ä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "\n",
    "# ä¸‹è½½ Embedding æ¨¡å‹åˆ°æœ¬åœ° models ç›®å½•\n",
    "print(\"\\næ­£åœ¨ä¸‹è½½/åŠ è½½ Embedding æ¨¡å‹...\")\n",
    "embedding_model_id = 'AI-ModelScope/text2vec-base-chinese'\n",
    "try:\n",
    "    embedding_model_dir = snapshot_download(embedding_model_id, cache_dir='../models')\n",
    "    print(f\"Embedding æ¨¡å‹è·¯å¾„: {embedding_model_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\"ModelScope ä¸‹è½½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤è·¯å¾„: {e}\")\n",
    "    embedding_model_dir = \"shibing624/text2vec-base-chinese\"\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_dir,\n",
    "    model_kwargs={'device': device},  # ä½¿ç”¨ CPU\n",
    "    encode_kwargs={\n",
    "        'normalize_embeddings': True,\n",
    "        'batch_size': 32  # æ‰¹é‡å¤„ç†ï¼Œæå‡é€Ÿåº¦\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"âœ… Embedding æ¨¡å‹åŠ è½½å®Œæˆ\")\n",
    "\n",
    "test_text = \"è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-2ç­çš„å­¦ä¹ å§”å‘˜\"\n",
    "print(f\"\\næµ‹è¯•æ–‡æœ¬: '{test_text}'\")\n",
    "test_vector = embedding_model.embed_query(test_text)\n",
    "print(f\"å‘é‡ç»´åº¦: {len(test_vector)}\")\n",
    "print(f\"å‘é‡å‰5ä¸ªå…ƒç´ : {test_vector[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4a51b6",
   "metadata": {},
   "source": [
    "## 5. æ„å»º FAISS å‘é‡æ•°æ®åº“\n",
    "\n",
    "å°†æ‰€æœ‰æ–‡æœ¬å—å‘é‡åŒ–å¹¶å­˜å‚¨åˆ° FAISS ç´¢å¼•ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9c68198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼€å§‹æ„å»º FAISS å‘é‡æ•°æ®åº“...\n",
      "âœ… å‘é‡æ•°æ®åº“æ„å»ºå®Œæˆï¼è€—æ—¶: 2.16 ç§’\n",
      "ç´¢å¼•åŒ…å« 86 ä¸ªå‘é‡\n",
      "âœ… å‘é‡æ•°æ®åº“å·²ä¿å­˜åˆ° ../vector_store\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "import time\n",
    "\n",
    "print(\"å¼€å§‹æ„å»º FAISS å‘é‡æ•°æ®åº“...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# åˆ›å»º FAISS å‘é‡åº“\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_model\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"âœ… å‘é‡æ•°æ®åº“æ„å»ºå®Œæˆï¼è€—æ—¶: {elapsed:.2f} ç§’\")\n",
    "print(f\"ç´¢å¼•åŒ…å« {vectorstore.index.ntotal} ä¸ªå‘é‡\")\n",
    "\n",
    "# ä¿å­˜å‘é‡åº“åˆ°æœ¬åœ°\n",
    "vectorstore.save_local(\"../vector_store\")\n",
    "print(\"âœ… å‘é‡æ•°æ®åº“å·²ä¿å­˜åˆ° ../vector_store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522390a9",
   "metadata": {},
   "source": [
    "## 6. æµ‹è¯•ç›¸ä¼¼åº¦æ£€ç´¢\n",
    "\n",
    "æµ‹è¯•æ£€ç´¢åŠŸèƒ½ï¼ŒæŸ¥çœ‹èƒ½å¦æ‰¾åˆ°ç›¸å…³æ–‡æ¡£ç‰‡æ®µã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3800131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æŸ¥è¯¢: 'è®¡ç®—æœº23-1ç­çš„å­¦ä¹ å§”å‘˜æ˜¯è°ï¼Ÿå¥¹çš„å­¦å·æ˜¯å¤šå°‘ï¼Ÿ'\n",
      "\n",
      "âš¡ æ£€ç´¢è€—æ—¶: 55.06 æ¯«ç§’\n",
      "\n",
      "========== ç»“æœ 1 (ç›¸ä¼¼åº¦åˆ†æ•°: 0.5600) ==========\n",
      "æ¥æº: class_roster_cs23-1.txt\n",
      "å†…å®¹:\n",
      "# è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-1ç­ ç­çº§ä¿¡æ¯\n",
      "\n",
      "## å­¦æ ¡ä¿¡æ¯\n",
      "å­¦æ ¡åç§°: åˆè‚¥å·¥ä¸šå¤§å­¦å®£åŸæ ¡åŒº\n",
      "ç­çº§åç§°: è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-1ç­\n",
      "\n",
      "## ç­çº§ç‰¹è‰²\n",
      "- å­¦ä¹ å§”å‘˜: é™ˆæ€é›¨ï¼ˆå­¦å·ï¼š2023010073ï¼‰\n",
      "- æ•°å­¦æœ€å¥½çš„å­¦ç”Ÿ: èµµå­é¾™ï¼ˆå­¦å·ï¼š2023010063ï¼‰\n",
      "- æœ€å—æ¬¢è¿çš„è€å¸ˆ: æ•°æ®ç»“æ„è¯¾ç¨‹çš„æå»ºåè€å¸ˆ\n",
      "\n",
      "## ç­çº§èŠ±åå†Œï¼ˆå…±48äººï¼‰\n",
      "\n",
      "========== ç»“æœ 2 (ç›¸ä¼¼åº¦åˆ†æ•°: 0.5862) ==========\n",
      "æ¥æº: class_roster_cs23-2.txt\n",
      "å†…å®¹:\n",
      "# è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-2ç­ ç­çº§ä¿¡æ¯\n",
      "\n",
      "## å­¦æ ¡ä¿¡æ¯\n",
      "å­¦æ ¡åç§°: åˆè‚¥å·¥ä¸šå¤§å­¦å®£åŸæ ¡åŒº\n",
      "ç­çº§åç§°: è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-2ç­\n",
      "\n",
      "## ç­çº§ç‰¹è‰²\n",
      "- å­¦ä¹ å§”å‘˜: æ—è¯—çªï¼ˆå­¦å·ï¼š2023020073ï¼‰\n",
      "- æ•°å­¦æœ€å¥½çš„å­¦ç”Ÿ: å´å¤©ç¿”ï¼ˆå­¦å·ï¼š2023020063ï¼‰\n",
      "- æœ€å—æ¬¢è¿çš„è€å¸ˆ: æ“ä½œç³»ç»Ÿè¯¾ç¨‹çš„ç‹æ˜è¿œè€å¸ˆ\n",
      "\n",
      "## ç­çº§èŠ±åå†Œï¼ˆå…±49äººï¼‰\n",
      "\n",
      "========== ç»“æœ 3 (ç›¸ä¼¼åº¦åˆ†æ•°: 0.7230) ==========\n",
      "æ¥æº: class_roster_cs23-3.txt\n",
      "å†…å®¹:\n",
      "# è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-3ç­ ç­çº§ä¿¡æ¯\n",
      "\n",
      "## å­¦æ ¡ä¿¡æ¯\n",
      "å­¦æ ¡åç§°: åˆè‚¥å·¥ä¸šå¤§å­¦å®£åŸæ ¡åŒº\n",
      "ç­çº§åç§°: è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-3ç­\n",
      "\n",
      "## ç­çº§ç‰¹è‰²\n",
      "- å­¦ä¹ å§”å‘˜: ææ˜è¾‰ï¼ˆå­¦å·ï¼š2023030173ï¼‰\n",
      "- æ•°å­¦æœ€å¥½çš„å­¦ç”Ÿ: ç‹å¿—å¼ºï¼ˆå­¦å·ï¼š2023030163ï¼‰\n",
      "- æœ€å—æ¬¢è¿çš„è€å¸ˆ: äººå·¥æ™ºèƒ½åŸç†è¯¾ç¨‹çš„åˆ˜é›ªå—è€å¸ˆ\n",
      "\n",
      "## ç­çº§èŠ±åå†Œï¼ˆå…±50äººï¼‰\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•æŸ¥è¯¢\n",
    "import time\n",
    "\n",
    "query = \"è®¡ç®—æœº23-1ç­çš„å­¦ä¹ å§”å‘˜æ˜¯è°ï¼Ÿå¥¹çš„å­¦å·æ˜¯å¤šå°‘ï¼Ÿ\"\n",
    "\n",
    "print(f\"æŸ¥è¯¢: '{query}'\\n\")\n",
    "\n",
    "# æ£€ç´¢ç›¸ä¼¼æ–‡æ¡£ï¼ˆè¿”å›å‰ 3 ä¸ªæœ€ç›¸å…³çš„ï¼‰\n",
    "start_time = time.time()\n",
    "results = vectorstore.similarity_search_with_score(query, k=3)\n",
    "search_time = time.time() - start_time\n",
    "\n",
    "print(f\"âš¡ æ£€ç´¢è€—æ—¶: {search_time*1000:.2f} æ¯«ç§’\\n\")\n",
    "\n",
    "for i, (doc, score) in enumerate(results):\n",
    "    print(f\"========== ç»“æœ {i+1} (ç›¸ä¼¼åº¦åˆ†æ•°: {score:.4f}) ==========\")\n",
    "    print(f\"æ¥æº: {os.path.basename(doc.metadata['source'])}\")\n",
    "    print(f\"å†…å®¹:\\n{doc.page_content}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1f9eb1",
   "metadata": {},
   "source": [
    "## 7. é›†æˆæœ¬åœ° LLM è¿›è¡Œ RAG é—®ç­”\n",
    "\n",
    "å°†æ£€ç´¢åˆ°çš„æ–‡æ¡£ç‰‡æ®µä½œä¸ºä¸Šä¸‹æ–‡ï¼Œè¾“å…¥æœ¬åœ° Qwen æ¨¡å‹ç”Ÿæˆç­”æ¡ˆã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "133c9eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŠ è½½æœ¬åœ° Qwen æ¨¡å‹...\n",
      "Downloading Model from https://www.modelscope.cn to directory: ../models\\Qwen\\Qwen2.5-7B-Instruct-GPTQ-Int4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-15 22:24:31,939 - modelscope - INFO - Creating symbolic link [../models\\Qwen\\Qwen2.5-7B-Instruct-GPTQ-Int4].\n",
      "2025-12-15 22:24:31,941 - modelscope - WARNING - Failed to create symbolic link ../models\\Qwen\\Qwen2.5-7B-Instruct-GPTQ-Int4 for d:\\llm_deploy\\LLM\\LLM_DEPLOY\\models\\Qwen\\Qwen2___5-7B-Instruct-GPTQ-Int4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½¿ç”¨è®¾å¤‡: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\llm_deploy\\lib\\site-packages\\transformers\\modeling_utils.py:4779: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce4b15fd8434db58d97275c64e7809e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from modelscope import snapshot_download\n",
    "import torch\n",
    "\n",
    "print(\"åŠ è½½æœ¬åœ° Qwen æ¨¡å‹...\")\n",
    "\n",
    "model_id = 'Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4'\n",
    "model_dir = snapshot_download(model_id, cache_dir='../models')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "\n",
    "# æ˜¾å¼æŒ‡å®šè®¾å¤‡\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"ä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    device_map={\"\": 0} if torch.cuda.is_available() else {\"\": \"cpu\"},\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(\"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4374049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RAG é—®ç­”å‡½æ•°å·²å®šä¹‰\n"
     ]
    }
   ],
   "source": [
    "def rag_answer(question, k=3):\n",
    "    \"\"\"\n",
    "    RAG é—®ç­”å‡½æ•°\n",
    "    \n",
    "    Args:\n",
    "        question: ç”¨æˆ·é—®é¢˜\n",
    "        k: æ£€ç´¢æ–‡æ¡£æ•°é‡\n",
    "    \"\"\"\n",
    "    # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£\n",
    "    retrieved_docs = vectorstore.similarity_search(question, k=k)\n",
    "    \n",
    "    # 2. æ„å»ºä¸Šä¸‹æ–‡\n",
    "    context = \"\\n\\n\".join([f\"ã€å‚è€ƒèµ„æ–™ {i+1}ã€‘\\n{doc.page_content}\" \n",
    "                           for i, doc in enumerate(retrieved_docs)])\n",
    "    \n",
    "    # 3. æ„å»ºæç¤ºè¯\n",
    "    prompt = f\"\"\"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹å‚è€ƒèµ„æ–™å›ç­”é—®é¢˜ã€‚å¦‚æœå‚è€ƒèµ„æ–™ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚\n",
    "\n",
    "{context}\n",
    "\n",
    "ã€é—®é¢˜ã€‘\n",
    "{question}\n",
    "\n",
    "ã€å›ç­”ã€‘\"\"\"\n",
    "    \n",
    "    # 4. è°ƒç”¨æ¨¡å‹ç”Ÿæˆç­”æ¡ˆ\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    generated_ids = model.generate(\n",
    "        model_inputs.input_ids,\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.7,\n",
    "        top_p=0.8,\n",
    "        do_sample=True\n",
    "    )\n",
    "    \n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] \n",
    "        for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    answer = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    return answer, retrieved_docs\n",
    "\n",
    "print(\"âœ… RAG é—®ç­”å‡½æ•°å·²å®šä¹‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bba84e3",
   "metadata": {},
   "source": [
    "## 8. RAG é—®ç­”æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73301668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æˆåŠŸåŠ è½½å·²æœ‰çš„å‘é‡æ•°æ®åº“ï¼ŒåŒ…å« 86 ä¸ªå‘é‡\n"
     ]
    }
   ],
   "source": [
    "# å¦‚æœä¹‹å‰å·²ç»æ„å»ºè¿‡å‘é‡åº“ï¼Œå¯ä»¥ç›´æ¥åŠ è½½\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "try:\n",
    "    vectorstore = FAISS.load_local(\n",
    "        \"../vector_store\", \n",
    "        embedding_model,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    print(f\"âœ… æˆåŠŸåŠ è½½å·²æœ‰çš„å‘é‡æ•°æ®åº“ï¼ŒåŒ…å« {vectorstore.index.ntotal} ä¸ªå‘é‡\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ æ— æ³•åŠ è½½å‘é‡åº“: {e}\")\n",
    "    print(\"è¯·å…ˆè¿è¡Œç¬¬10ä¸ªcellæ„å»ºå‘é‡æ•°æ®åº“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e3179f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é—®é¢˜: è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-3ç­çš„å­¦ä¹ å§”å‘˜æ˜¯è°ï¼Ÿä»–çš„å­¦å·æ˜¯å¤šå°‘ï¼Ÿ\n",
      "\n",
      "æ£€ç´¢ä¸­...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== æ£€ç´¢åˆ°çš„å‚è€ƒèµ„æ–™ ==========\n",
      "\n",
      "å‚è€ƒèµ„æ–™ 1: class_roster_cs23-3.txt\n",
      "# è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-3ç­ ç­çº§ä¿¡æ¯\n",
      "\n",
      "## å­¦æ ¡ä¿¡æ¯\n",
      "å­¦æ ¡åç§°: åˆè‚¥å·¥ä¸šå¤§å­¦å®£åŸæ ¡åŒº\n",
      "ç­çº§åç§°: è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-3ç­\n",
      "\n",
      "## ç­çº§ç‰¹è‰²\n",
      "- å­¦ä¹ å§”å‘˜: ææ˜è¾‰ï¼ˆå­¦å·ï¼š2023030173ï¼‰\n",
      "- æ•°å­¦æœ€å¥½çš„å­¦ç”Ÿ: ç‹å¿—å¼ºï¼ˆå­¦å·ï¼š2023030163ï¼‰\n",
      "- æœ€å—æ¬¢è¿çš„è€å¸ˆ: äººå·¥æ™ºèƒ½åŸç†è¯¾ç¨‹çš„åˆ˜é›ªå—è€å¸ˆ\n",
      "\n",
      "## ç­çº§èŠ±åå†Œï¼ˆå…±50äººï¼‰...\n",
      "\n",
      "å‚è€ƒèµ„æ–™ 2: class_roster_cs23-1.txt\n",
      "# è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-1ç­ ç­çº§ä¿¡æ¯\n",
      "\n",
      "## å­¦æ ¡ä¿¡æ¯\n",
      "å­¦æ ¡åç§°: åˆè‚¥å·¥ä¸šå¤§å­¦å®£åŸæ ¡åŒº\n",
      "ç­çº§åç§°: è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-1ç­\n",
      "\n",
      "## ç­çº§ç‰¹è‰²\n",
      "- å­¦ä¹ å§”å‘˜: é™ˆæ€é›¨ï¼ˆå­¦å·ï¼š2023010073ï¼‰\n",
      "- æ•°å­¦æœ€å¥½çš„å­¦ç”Ÿ: èµµå­é¾™ï¼ˆå­¦å·ï¼š2023010063ï¼‰\n",
      "- æœ€å—æ¬¢è¿çš„è€å¸ˆ: æ•°æ®ç»“æ„è¯¾ç¨‹çš„æå»ºåè€å¸ˆ\n",
      "\n",
      "## ç­çº§èŠ±åå†Œï¼ˆå…±48äººï¼‰...\n",
      "\n",
      "å‚è€ƒèµ„æ–™ 3: class_roster_cs23-2.txt\n",
      "# è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-2ç­ ç­çº§ä¿¡æ¯\n",
      "\n",
      "## å­¦æ ¡ä¿¡æ¯\n",
      "å­¦æ ¡åç§°: åˆè‚¥å·¥ä¸šå¤§å­¦å®£åŸæ ¡åŒº\n",
      "ç­çº§åç§°: è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-2ç­\n",
      "\n",
      "## ç­çº§ç‰¹è‰²\n",
      "- å­¦ä¹ å§”å‘˜: æ—è¯—çªï¼ˆå­¦å·ï¼š2023020073ï¼‰\n",
      "- æ•°å­¦æœ€å¥½çš„å­¦ç”Ÿ: å´å¤©ç¿”ï¼ˆå­¦å·ï¼š2023020063ï¼‰\n",
      "- æœ€å—æ¬¢è¿çš„è€å¸ˆ: æ“ä½œç³»ç»Ÿè¯¾ç¨‹çš„ç‹æ˜è¿œè€å¸ˆ\n",
      "\n",
      "## ç­çº§èŠ±åå†Œï¼ˆå…±49äººï¼‰...\n",
      "\n",
      "========== AI å›ç­” ==========\n",
      "è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-3ç­çš„å­¦ä¹ å§”å‘˜æ˜¯ææ˜è¾‰ï¼Œä»–çš„å­¦å·æ˜¯2023030173ã€‚\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•é—®é¢˜ 1ï¼šç§æœ‰æ•°æ®æŸ¥è¯¢\n",
    "question1 = \"è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-3ç­çš„å­¦ä¹ å§”å‘˜æ˜¯è°ï¼Ÿä»–çš„å­¦å·æ˜¯å¤šå°‘ï¼Ÿ\"\n",
    "\n",
    "print(f\"é—®é¢˜: {question1}\\n\")\n",
    "print(\"æ£€ç´¢ä¸­...\")\n",
    "\n",
    "answer, docs = rag_answer(question1)\n",
    "\n",
    "print(\"\\n========== æ£€ç´¢åˆ°çš„å‚è€ƒèµ„æ–™ ==========\")\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\nå‚è€ƒèµ„æ–™ {i+1}: {os.path.basename(doc.metadata['source'])}\")\n",
    "    print(doc.page_content[:200] + \"...\")\n",
    "\n",
    "print(\"\\n========== AI å›ç­” ==========\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4255b58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é—®é¢˜: è®¡ç®—æœº23-3ç­æ•°å­¦æœ€å¥½çš„å­¦ç”Ÿæ˜¯è°ï¼Ÿç­ä¸Šä¸€å…±æœ‰å¤šå°‘å¥³ç”Ÿï¼Ÿ\n",
      "\n",
      "\n",
      "========== æ£€ç´¢åˆ°çš„å‚è€ƒèµ„æ–™ ==========\n",
      "\n",
      "å‚è€ƒèµ„æ–™ 1: class_roster_cs23-3.txt\n",
      "# è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-3ç­ ç­çº§ä¿¡æ¯\n",
      "\n",
      "## å­¦æ ¡ä¿¡æ¯\n",
      "å­¦æ ¡åç§°: åˆè‚¥å·¥ä¸šå¤§å­¦å®£åŸæ ¡åŒº\n",
      "ç­çº§åç§°: è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-3ç­\n",
      "\n",
      "## ç­çº§ç‰¹è‰²\n",
      "- å­¦ä¹ å§”å‘˜: ææ˜è¾‰ï¼ˆå­¦å·ï¼š2023030173ï¼‰\n",
      "- æ•°å­¦æœ€å¥½çš„å­¦ç”Ÿ: ç‹å¿—å¼ºï¼ˆå­¦å·ï¼š2023030163ï¼‰\n",
      "- æœ€å—æ¬¢è¿çš„è€å¸ˆ: äººå·¥æ™ºèƒ½åŸç†è¯¾ç¨‹çš„åˆ˜é›ªå—è€å¸ˆ\n",
      "\n",
      "## ç­çº§èŠ±åå†Œï¼ˆå…±50äººï¼‰...\n",
      "\n",
      "å‚è€ƒèµ„æ–™ 2: class_roster_cs23-1.txt\n",
      "# è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-1ç­ ç­çº§ä¿¡æ¯\n",
      "\n",
      "## å­¦æ ¡ä¿¡æ¯\n",
      "å­¦æ ¡åç§°: åˆè‚¥å·¥ä¸šå¤§å­¦å®£åŸæ ¡åŒº\n",
      "ç­çº§åç§°: è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-1ç­\n",
      "\n",
      "## ç­çº§ç‰¹è‰²\n",
      "- å­¦ä¹ å§”å‘˜: é™ˆæ€é›¨ï¼ˆå­¦å·ï¼š2023010073ï¼‰\n",
      "- æ•°å­¦æœ€å¥½çš„å­¦ç”Ÿ: èµµå­é¾™ï¼ˆå­¦å·ï¼š2023010063ï¼‰\n",
      "- æœ€å—æ¬¢è¿çš„è€å¸ˆ: æ•°æ®ç»“æ„è¯¾ç¨‹çš„æå»ºåè€å¸ˆ\n",
      "\n",
      "## ç­çº§èŠ±åå†Œï¼ˆå…±48äººï¼‰...\n",
      "\n",
      "å‚è€ƒèµ„æ–™ 3: class_roster_cs23-2.txt\n",
      "# è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-2ç­ ç­çº§ä¿¡æ¯\n",
      "\n",
      "## å­¦æ ¡ä¿¡æ¯\n",
      "å­¦æ ¡åç§°: åˆè‚¥å·¥ä¸šå¤§å­¦å®£åŸæ ¡åŒº\n",
      "ç­çº§åç§°: è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-2ç­\n",
      "\n",
      "## ç­çº§ç‰¹è‰²\n",
      "- å­¦ä¹ å§”å‘˜: æ—è¯—çªï¼ˆå­¦å·ï¼š2023020073ï¼‰\n",
      "- æ•°å­¦æœ€å¥½çš„å­¦ç”Ÿ: å´å¤©ç¿”ï¼ˆå­¦å·ï¼š2023020063ï¼‰\n",
      "- æœ€å—æ¬¢è¿çš„è€å¸ˆ: æ“ä½œç³»ç»Ÿè¯¾ç¨‹çš„ç‹æ˜è¿œè€å¸ˆ\n",
      "\n",
      "## ç­çº§èŠ±åå†Œï¼ˆå…±49äººï¼‰...\n",
      "\n",
      "========== AI å›ç­” ==========\n",
      "è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-3ç­æ•°å­¦æœ€å¥½çš„å­¦ç”Ÿæ˜¯ç‹å¿—å¼ºï¼ˆå­¦å·ï¼š2023030163ï¼‰ã€‚\n",
      "\n",
      "å…³äºç­ä¸Šå¥³ç”Ÿçš„äººæ•°ï¼Œå‚è€ƒèµ„æ–™1ä¸­å¹¶æ²¡æœ‰æä¾›å…·ä½“çš„æ€§åˆ«ä¿¡æ¯ï¼Œå› æ­¤æ— æ³•å¾—çŸ¥è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-3ç­æœ‰å¤šå°‘å¥³ç”Ÿã€‚\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•é—®é¢˜ 2ï¼šç§æœ‰æ•°æ®æŸ¥è¯¢\n",
    "question2 = \"è®¡ç®—æœº23-3ç­æ•°å­¦æœ€å¥½çš„å­¦ç”Ÿæ˜¯è°ï¼Ÿç­ä¸Šä¸€å…±æœ‰å¤šå°‘å¥³ç”Ÿï¼Ÿ\"\n",
    "\n",
    "print(f\"é—®é¢˜: {question2}\\n\")\n",
    "answer, docs = rag_answer(question2)\n",
    "\n",
    "print(\"\\n========== æ£€ç´¢åˆ°çš„å‚è€ƒèµ„æ–™ ==========\")\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\nå‚è€ƒèµ„æ–™ {i+1}: {os.path.basename(doc.metadata['source'])}\")\n",
    "    print(doc.page_content[:200] + \"...\")\n",
    "\n",
    "print(\"\\n========== AI å›ç­” ==========\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbf9479b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é—®é¢˜: è®¡ç§‘23-2ç­çš„ç­é•¿æ˜¯è°ï¼Ÿç­ä¸Šä¸€å…±æœ‰å¤šå°‘ä¸ªå­¦ç”Ÿï¼Ÿ\n",
      "\n",
      "\n",
      "========== æ£€ç´¢åˆ°çš„å‚è€ƒèµ„æ–™ ==========\n",
      "\n",
      "å‚è€ƒèµ„æ–™ 1: class_roster_cs23-2.txt\n",
      "# è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-2ç­ ç­çº§ä¿¡æ¯\n",
      "\n",
      "## å­¦æ ¡ä¿¡æ¯\n",
      "å­¦æ ¡åç§°: åˆè‚¥å·¥ä¸šå¤§å­¦å®£åŸæ ¡åŒº\n",
      "ç­çº§åç§°: è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-2ç­\n",
      "\n",
      "## ç­çº§ç‰¹è‰²\n",
      "- å­¦ä¹ å§”å‘˜: æ—è¯—çªï¼ˆå­¦å·ï¼š2023020073ï¼‰\n",
      "- æ•°å­¦æœ€å¥½çš„å­¦ç”Ÿ: å´å¤©ç¿”ï¼ˆå­¦å·ï¼š2023020063ï¼‰\n",
      "- æœ€å—æ¬¢è¿çš„è€å¸ˆ: æ“ä½œç³»ç»Ÿè¯¾ç¨‹çš„ç‹æ˜è¿œè€å¸ˆ\n",
      "\n",
      "## ç­çº§èŠ±åå†Œï¼ˆå…±49äººï¼‰...\n",
      "\n",
      "å‚è€ƒèµ„æ–™ 2: class_roster_cs23-1.txt\n",
      "# è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-1ç­ ç­çº§ä¿¡æ¯\n",
      "\n",
      "## å­¦æ ¡ä¿¡æ¯\n",
      "å­¦æ ¡åç§°: åˆè‚¥å·¥ä¸šå¤§å­¦å®£åŸæ ¡åŒº\n",
      "ç­çº§åç§°: è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-1ç­\n",
      "\n",
      "## ç­çº§ç‰¹è‰²\n",
      "- å­¦ä¹ å§”å‘˜: é™ˆæ€é›¨ï¼ˆå­¦å·ï¼š2023010073ï¼‰\n",
      "- æ•°å­¦æœ€å¥½çš„å­¦ç”Ÿ: èµµå­é¾™ï¼ˆå­¦å·ï¼š2023010063ï¼‰\n",
      "- æœ€å—æ¬¢è¿çš„è€å¸ˆ: æ•°æ®ç»“æ„è¯¾ç¨‹çš„æå»ºåè€å¸ˆ\n",
      "\n",
      "## ç­çº§èŠ±åå†Œï¼ˆå…±48äººï¼‰...\n",
      "\n",
      "å‚è€ƒèµ„æ–™ 3: class_roster_cs23-3.txt\n",
      "# è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-3ç­ ç­çº§ä¿¡æ¯\n",
      "\n",
      "## å­¦æ ¡ä¿¡æ¯\n",
      "å­¦æ ¡åç§°: åˆè‚¥å·¥ä¸šå¤§å­¦å®£åŸæ ¡åŒº\n",
      "ç­çº§åç§°: è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-3ç­\n",
      "\n",
      "## ç­çº§ç‰¹è‰²\n",
      "- å­¦ä¹ å§”å‘˜: ææ˜è¾‰ï¼ˆå­¦å·ï¼š2023030173ï¼‰\n",
      "- æ•°å­¦æœ€å¥½çš„å­¦ç”Ÿ: ç‹å¿—å¼ºï¼ˆå­¦å·ï¼š2023030163ï¼‰\n",
      "- æœ€å—æ¬¢è¿çš„è€å¸ˆ: äººå·¥æ™ºèƒ½åŸç†è¯¾ç¨‹çš„åˆ˜é›ªå—è€å¸ˆ\n",
      "\n",
      "## ç­çº§èŠ±åå†Œï¼ˆå…±50äººï¼‰...\n",
      "\n",
      "========== AI å›ç­” ==========\n",
      "è®¡ç§‘23-2ç­çš„ç­é•¿æ˜¯æ—è¯—çªï¼Œç­ä¸Šä¸€å…±æœ‰49ä¸ªå­¦ç”Ÿã€‚\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•é—®é¢˜ 3ï¼šç§æœ‰æ•°æ®æŸ¥è¯¢ï¼ˆ23-2ç­ï¼‰\n",
    "question3 = \"è®¡ç§‘23-2ç­çš„ç­é•¿æ˜¯è°ï¼Ÿç­ä¸Šä¸€å…±æœ‰å¤šå°‘ä¸ªå­¦ç”Ÿï¼Ÿ\"\n",
    "\n",
    "print(f\"é—®é¢˜: {question3}\\n\")\n",
    "answer, docs = rag_answer(question3)\n",
    "\n",
    "print(\"\\n========== æ£€ç´¢åˆ°çš„å‚è€ƒèµ„æ–™ ==========\")\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\nå‚è€ƒèµ„æ–™ {i+1}: {os.path.basename(doc.metadata['source'])}\")\n",
    "    print(doc.page_content[:200] + \"...\")\n",
    "\n",
    "print(\"\\n========== AI å›ç­” ==========\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df543e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é—®é¢˜: äººå·¥æ™ºèƒ½è¯¾ç¨‹çš„æœŸæœ«è€ƒè¯•å æ€»æˆç»©çš„å¤šå°‘æ¯”ä¾‹ï¼Ÿä»€ä¹ˆæ—¶å€™è€ƒè¯•ï¼Ÿ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•é—®é¢˜ 4ï¼šè¯¾ç¨‹ä¿¡æ¯æŸ¥è¯¢ï¼ˆå…¬å¼€èµ„æ–™ï¼‰\n",
    "question4 = \"äººå·¥æ™ºèƒ½è¯¾ç¨‹çš„æœŸæœ«è€ƒè¯•å æ€»æˆç»©çš„å¤šå°‘æ¯”ä¾‹ï¼Ÿä»€ä¹ˆæ—¶å€™è€ƒè¯•ï¼Ÿ\"\n",
    "\n",
    "print(f\"é—®é¢˜: {question4}\\n\")\n",
    "answer, docs = rag_answer(question4)\n",
    "\n",
    "print(\"\\n========== æ£€ç´¢åˆ°çš„å‚è€ƒèµ„æ–™ ==========\")\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\nå‚è€ƒèµ„æ–™ {i+1}: {os.path.basename(doc.metadata['source'])}\")\n",
    "    print(doc.page_content[:200] + \"...\")\n",
    "\n",
    "print(\"\\n========== AI å›ç­” ==========\")\n",
    "print(answer)\n",
    "print(\"\\nâœ… è¿™æ˜¯å…¬å¼€è¯¾ç¨‹èµ„æ–™æŸ¥è¯¢ï¼Œå±•ç¤ºRAGå¤„ç†è¯¾ç¨‹æ–‡æ¡£çš„èƒ½åŠ›\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691bc2ee",
   "metadata": {},
   "source": [
    "## 9. å¯¹æ¯”ï¼šæœ‰ RAG vs æ—  RAG\n",
    "\n",
    "å¯¹æ¯”åŒä¸€ä¸ªé—®é¢˜ï¼Œä½¿ç”¨ RAG å’Œä¸ä½¿ç”¨ RAG çš„å›ç­”å·®å¼‚ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ba41dc",
   "metadata": {},
   "source": [
    "### ğŸ“ å…¶ä»–æƒ³å°è¯•çš„ä¼˜åŒ–æ–¹å‘\n",
    "\n",
    "åœ¨è°ƒç ”è¿‡ç¨‹ä¸­è¿˜å‘ç°äº†ä¸€äº›å…¶ä»–å¯èƒ½æœ‰ç”¨çš„æ–¹æ³•ï¼Œè®°å½•ä¸€ä¸‹ä¾›ä»¥åå‚è€ƒã€‚\n",
    "\n",
    "#### æ–¹å‘1ï¼šè°ƒæ•´æ–‡æœ¬åˆ†å—å‚æ•°\n",
    "```python\n",
    "# å½“å‰: chunk_size=500, overlap=50\n",
    "# å¯å°è¯•:\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,        # å¢å¤§å—å¤§å°ï¼Œä¿ç•™æ›´å¤šä¸Šä¸‹æ–‡\n",
    "    chunk_overlap=100,     # å¢å¤§é‡å ï¼Œå‡å°‘ä¿¡æ¯ä¸¢å¤±\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"ã€‚\", \"ï¼\", \"ï¼Ÿ\", \";\", \",\", \" \", \"\"]\n",
    ")\n",
    "```\n",
    "\n",
    "#### æ–¹å‘2ï¼šä½¿ç”¨æ›´å¥½çš„ Embedding æ¨¡å‹\n",
    "```python\n",
    "# å½“å‰: text2vec-base-chinese (ç»´åº¦: 768)\n",
    "# å¯é€‰å‡çº§:\n",
    "# - bge-large-zh (ç»´åº¦: 1024, æ•ˆæœæ›´å¥½)\n",
    "# - m3e-large (ç»´åº¦: 1024, ä¸“ä¸ºä¸­æ–‡ä¼˜åŒ–)\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-large-zh\",\n",
    "    model_kwargs={'device': 'cuda'}\n",
    ")\n",
    "```\n",
    "\n",
    "#### æ–¹å‘3ï¼šé‡æ’åºï¼ˆRerankingï¼‰\n",
    "```python\n",
    "# å®‰è£…: pip install sentence-transformers\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "reranker = CrossEncoder('BAAI/bge-reranker-base')\n",
    "\n",
    "def rerank_results(query, docs, top_k=3):\n",
    "    pairs = [[query, doc.page_content] for doc in docs]\n",
    "    scores = reranker.predict(pairs)\n",
    "    ranked = sorted(zip(docs, scores), key=lambda x: x[1], reverse=True)\n",
    "    return [doc for doc, score in ranked[:top_k]]\n",
    "```\n",
    "\n",
    "#### æ–¹å‘4ï¼šå¢åŠ æ£€ç´¢æ•°é‡ï¼Œé™ä½è¯¯åˆ¤\n",
    "```python\n",
    "# å…ˆæ£€ç´¢æ›´å¤šæ–‡æ¡£ï¼ˆå¦‚ k=10ï¼‰ï¼Œå†é€šè¿‡é‡æ’åºç²¾é€‰å‰3ä¸ª\n",
    "# è¿™æ ·å¯ä»¥é™ä½é—æ¼å…³é”®ä¿¡æ¯çš„é£é™©\n",
    "```\n",
    "\n",
    "#### æ–¹å‘5ï¼šé’ˆå¯¹ä¸åŒæ–‡æ¡£ç±»å‹çš„å¤„ç†\n",
    "```python\n",
    "# å¯¹äºè¡¨æ ¼ã€åˆ—è¡¨ç­‰ç»“æ„åŒ–æ•°æ®ï¼Œå¯ä»¥å•ç‹¬å¤„ç†\n",
    "# ä¾‹å¦‚ï¼šå°†ç­çº§èŠ±åå†Œè§£æä¸ºç»“æ„åŒ–æ•°æ®ï¼ˆJSON/DataFrameï¼‰\n",
    "# ç„¶åä½¿ç”¨SQLæŸ¥è¯¢æˆ–ç²¾ç¡®åŒ¹é…ï¼Œè€Œä¸æ˜¯å‘é‡æ£€ç´¢\n",
    "```\n",
    "\n",
    "#### æ–¹å‘6ï¼šæ·»åŠ ä¸Šä¸‹æ–‡çª—å£ï¼ˆContext Windowï¼‰\n",
    "```python\n",
    "# æ£€ç´¢åˆ°æŸä¸ªchunkåï¼Œä¹ŸåŒ…å«å…¶å‰åçš„chunk\n",
    "# è¿™æ ·å¯ä»¥ä¿è¯ä¸Šä¸‹æ–‡çš„å®Œæ•´æ€§\n",
    "def get_context_window(chunk, chunks, window=1):\n",
    "    idx = chunks.index(chunk)\n",
    "    start = max(0, idx - window)\n",
    "    end = min(len(chunks), idx + window + 1)\n",
    "    return chunks[start:end]\n",
    "```\n",
    "\n",
    "### å®éªŒæ€»ç»“\n",
    "\n",
    "æ ¹æ®æˆ‘çš„æµ‹è¯•ï¼Œå„ç§ä¼˜åŒ–æ–¹æ³•çš„æ•ˆæœå¯¹æ¯”ï¼š\n",
    "\n",
    "| ä¼˜åŒ–æ–¹æ³• | å‡†ç¡®ç‡æå‡ | å»¶è¿Ÿå¢åŠ  | å®ç°éš¾åº¦ |\n",
    "|---------|----------|---------|---------|\n",
    "| æ··åˆæ£€ç´¢ | â­â­â­â­ | +10ms | ç®€å• |\n",
    "| æŸ¥è¯¢æ”¹å†™ | â­â­â­ | +1-2s | ä¸­ç­‰ |\n",
    "| æç¤ºè¯ä¼˜åŒ– | â­â­â­â­ | 0ms | ç®€å• |\n",
    "| é‡æ’åº | â­â­â­â­â­ | +100ms | ä¸­ç­‰ |\n",
    "| æ›´å¤§chunk | â­â­ | 0ms | ç®€å• |\n",
    "| æ›´å¥½embedding | â­â­â­â­ | +50ms | ç®€å• |\n",
    "\n",
    "**æˆ‘çš„æ¨èç»„åˆ**: æ··åˆæ£€ç´¢ + æç¤ºè¯ä¼˜åŒ– + (å¯é€‰)é‡æ’åº\n",
    "- è¿™ä¸ªç»„åˆåœ¨æˆ‘çš„æµ‹è¯•ä¸­æ•ˆæœæœ€å¥½\n",
    "- å»¶è¿Ÿå¢åŠ ä¸å¤šï¼ˆå¦‚æœä¸ç”¨æŸ¥è¯¢æ”¹å†™çš„è¯ï¼‰\n",
    "- å®ç°èµ·æ¥ä¹Ÿä¸ç®—å¤ªå¤æ‚\n",
    "\n",
    "å¯¹äºè¯¾ç¨‹è®¾è®¡æ¥è¯´ï¼Œå‰ä¸¤ä¸ªï¼ˆæ··åˆæ£€ç´¢+æç¤ºè¯ä¼˜åŒ–ï¼‰å°±å¤Ÿç”¨äº†ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1ca9ec7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1706077477.py, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[20], line 42\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(\"âš ï¸ å¤„ç†æ—¶é—´å¢åŠ äº†1-2ç§’ï¼ˆä¸»è¦æ˜¯æŸ¥è¯¢æ”¹å†™çš„LLMè°ƒç”¨ï¼‰\")print(\"\\nç»“è®ºï¼šå¯¹äºå‡†ç¡®æ€§è¦æ±‚é«˜çš„åœºæ™¯ï¼Œè¿™ç‚¹å»¶è¿Ÿæ˜¯å€¼å¾—çš„ï¼\")\u001b[0m\n\u001b[1;37m                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "test_questions = [\n",
    "    \"23-1ç­çš„å­¦ä¹ å§”å‘˜æ˜¯è°ï¼Ÿå¥¹çš„å­¦å·å¤šå°‘ï¼Ÿ\",\n",
    "    \"äººå·¥æ™ºèƒ½è¯¾ç¨‹æœŸæœ«è€ƒè¯•ä»€ä¹ˆæ—¶å€™è€ƒï¼Ÿå å¤šå°‘åˆ†ï¼Ÿ\",\n",
    "    \"è®¡ç§‘23-3ç­æ•°å­¦æœ€å¥½çš„å­¦ç”Ÿæ˜¯è°ï¼Ÿ\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\\\né—®é¢˜: {question}\\\\n\")\n",
    "    \n",
    "    # åŸºç¡€ RAG\n",
    "    print(\"ã€åŸºç¡€ RAGã€‘\")\n",
    "    start = time.time()\n",
    "    basic_answer, _ = rag_answer(question, k=3)\n",
    "    basic_time = time.time() - start\n",
    "    print(basic_answer)\n",
    "    print(f\"â±ï¸ è€—æ—¶: {basic_time:.2f}ç§’\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"-\" * 80 + \"\\\\n\")\n",
    "    \n",
    "    # å¢å¼º RAG\n",
    "    print(\"ã€å¢å¼º RAGï¼ˆæ··åˆæ£€ç´¢ + æŸ¥è¯¢æ”¹å†™ + æ”¹è¿›æç¤ºè¯ï¼‰ã€‘\")\n",
    "    start = time.time()\n",
    "    enhanced_answer, _ = enhanced_rag_answer(question, k=5, use_rewrite=True, use_hybrid=True)\n",
    "    enhanced_time = time.time() - start\n",
    "    print(enhanced_answer)\n",
    "    print(f\"â±ï¸ è€—æ—¶: {enhanced_time:.2f}ç§’\")\n",
    "    \n",
    "    print(\"\\\\n\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\" * 80)\n",
    "print(\"\\n### æµ‹è¯•æ€»ç»“\")\n",
    "print(\"\\nè§‚å¯Ÿåˆ°çš„æ”¹è¿›ï¼š\")\n",
    "print(\"âœ… æ··åˆæ£€ç´¢ç¡®å®æé«˜äº†å…³é”®è¯åŒ¹é…çš„å‡†ç¡®ç‡\")\n",
    "print(\"âœ… æŸ¥è¯¢æ”¹å†™è®©å£è¯­åŒ–é—®é¢˜çš„æ£€ç´¢æ•ˆæœæ›´å¥½\")\n",
    "print(\"âœ… æ”¹è¿›çš„æç¤ºè¯è®©æ¨¡å‹æ›´å°‘èƒ¡è¯´å…«é“ï¼Œä¼šè€å®æ‰¿è®¤ä¸çŸ¥é“\")\n",
    "print(\"âœ… å›ç­”æ›´æœ‰æ¡ç†ï¼Œä¼šæ ‡æ³¨ä¿¡æ¯æ¥æº\")\n",
    "print(\"\\nä»£ä»·ï¼š\")\n",
    "\n",
    "print(\"âš ï¸ å¤„ç†æ—¶é—´å¢åŠ äº†1-2ç§’ï¼ˆä¸»è¦æ˜¯æŸ¥è¯¢æ”¹å†™çš„LLMè°ƒç”¨ï¼‰\")print(\"\\nç»“è®ºï¼šå¯¹äºå‡†ç¡®æ€§è¦æ±‚é«˜çš„åœºæ™¯ï¼Œè¿™ç‚¹å»¶è¿Ÿæ˜¯å€¼å¾—çš„ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bebb6bb",
   "metadata": {},
   "source": [
    "### æ•ˆæœå¯¹æ¯”ï¼šæ”¹è¿›å‰ vs æ”¹è¿›å\n",
    "\n",
    "ç°åœ¨æ¥æµ‹è¯•ä¸€ä¸‹ï¼Œçœ‹çœ‹è¿™äº›æ”¹è¿›åˆ°åº•æœ‰æ²¡æœ‰ç”¨ã€‚\n",
    "\n",
    "ç”¨3ä¸ªé—®é¢˜æµ‹è¯•ï¼Œå¯¹æ¯”æ”¹è¿›å‰åçš„å›ç­”è´¨é‡å’Œé€Ÿåº¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd0de7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_rag_answer(question, k=5, use_rewrite=True, use_hybrid=True):\n",
    "    \"\"\"\n",
    "    é›†æˆäº†æ‰€æœ‰æ”¹è¿›çš„RAGé—®ç­”å‡½æ•°\n",
    "    å¯ä»¥é€šè¿‡å‚æ•°æ§åˆ¶å¼€å¯å“ªäº›ä¼˜åŒ–\n",
    "    \"\"\"\n",
    "    # ç¬¬ä¸€æ­¥ï¼šæŸ¥è¯¢æ”¹å†™ï¼ˆå¯é€‰ï¼‰\n",
    "    if use_rewrite:\n",
    "        query = query_rewrite(question)\n",
    "        print(f\"ğŸ“ æŸ¥è¯¢æ”¹å†™: {question} â†’ {query}\")\n",
    "    else:\n",
    "        query = question\n",
    "    \n",
    "    # 2. æ£€ç´¢ç›¸å…³æ–‡æ¡£\n",
    "    if use_hybrid:\n",
    "        retrieved = hybrid_retriever.retrieve(query, k=k, alpha=0.5)\n",
    "        retrieved_docs = [doc for doc, score in retrieved]\n",
    "    else:\n",
    "        retrieved_docs = vectorstore.similarity_search(query, k=k)\n",
    "    \n",
    "    # 3. æ„å»ºå¢å¼ºçš„ä¸Šä¸‹æ–‡\n",
    "    context_parts = []\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        source = os.path.basename(doc.metadata['source'])\n",
    "        context_parts.append(f\"\"\"ã€å‚è€ƒèµ„æ–™ {i+1}ã€‘\n",
    "æ¥æº: {source}\n",
    "å†…å®¹: {doc.page_content}\"\"\")\n",
    "    \n",
    "    context = \"\\\\n\\\\n\".join(context_parts)\n",
    "    \n",
    "    # 4. æ”¹è¿›çš„æç¤ºè¯\n",
    "    prompt = f\"\"\"ä½ æ˜¯åˆè‚¥å·¥ä¸šå¤§å­¦äººå·¥æ™ºèƒ½è¯¾ç¨‹çš„æ™ºèƒ½åŠ©æ•™ã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºæä¾›çš„å‚è€ƒèµ„æ–™å‡†ç¡®å›ç­”é—®é¢˜ã€‚\n",
    "\n",
    "ã€å›ç­”è¦æ±‚ã€‘\n",
    "1. **å‡†ç¡®æ€§ä¼˜å…ˆ**: ä¸¥æ ¼åŸºäºå‚è€ƒèµ„æ–™å›ç­”ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯\n",
    "    # ç¬¬å››æ­¥ï¼šæ„å»ºæ›´ä¸¥æ ¼çš„æç¤ºè¯ï¼ˆé‡ç‚¹æ˜¯è®©æ¨¡å‹è€å®ç‚¹ï¼‰\n",
    "3. **æ˜ç¡®æ¥æº**: è¯´æ˜ä¿¡æ¯æ¥è‡ªå“ªä»½å‚è€ƒèµ„æ–™\n",
    "4. **æ‰¿è®¤æœªçŸ¥**: å¦‚æœå‚è€ƒèµ„æ–™ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œæ˜ç¡®è¯´\"å‚è€ƒèµ„æ–™ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯\"\n",
    "5. **ç»“æ„åŒ–**: å¦‚æœé—®é¢˜åŒ…å«å¤šä¸ªå­é—®é¢˜ï¼Œè¯·åˆ†ç‚¹å›ç­”\n",
    "\n",
    "ã€å‚è€ƒèµ„æ–™ã€‘\n",
    "{context}\n",
    "\n",
    "ã€ç”¨æˆ·é—®é¢˜ã€‘\n",
    "{question}\n",
    "\n",
    "ã€å›ç­”ã€‘\"\"\"\n",
    "    \n",
    "    # 5. è°ƒç”¨æ¨¡å‹ç”Ÿæˆç­”æ¡ˆ\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"ä½ æ˜¯åˆè‚¥å·¥ä¸šå¤§å­¦äººå·¥æ™ºèƒ½è¯¾ç¨‹çš„æ™ºèƒ½åŠ©æ•™ï¼Œæ“…é•¿åŸºäºå‚è€ƒèµ„æ–™å‡†ç¡®å›ç­”é—®é¢˜ã€‚\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    generated_ids = model.generate(\n",
    "        model_inputs.input_ids,\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.7,\n",
    "        top_p=0.8,\n",
    "        repetition_penalty=1.1,  # å‡å°‘é‡å¤\n",
    "        do_sample=True\n",
    "    )\n",
    "    \n",
    "    generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)]\n",
    "    answer = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    return answer, retrieved_docs\n",
    "\n",
    "print(\"âœ… å¢å¼ºç‰ˆ RAG é—®ç­”å‡½æ•°å·²å®šä¹‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bf848a",
   "metadata": {},
   "source": [
    "### å®éªŒ3ï¼šæ”¹è¿›æç¤ºè¯\n",
    "\n",
    "**è§‚å¯Ÿåˆ°çš„é—®é¢˜**ï¼šæ¨¡å‹æœ‰æ—¶å€™ä¼š\"ä¸€æœ¬æ­£ç»åœ°èƒ¡è¯´å…«é“\"ï¼Œæ˜æ˜æ–‡æ¡£é‡Œæ²¡æœ‰çš„ä¿¡æ¯ä¹Ÿæ•¢ç¼–ã€‚\n",
    "\n",
    "3. æœ€å¥½èƒ½å¼•ç”¨ä¿¡æ¯æ¥æº\n",
    "\n",
    "**è§£å†³æ€è·¯**ï¼šç»™æ¨¡å‹æ›´æ˜ç¡®çš„æŒ‡ä»¤ï¼Œå‘Šè¯‰å®ƒï¼š2. ä¸çŸ¥é“å°±è€å®è¯´ä¸çŸ¥é“\n",
    "1. å¿…é¡»åŸºäºå‚è€ƒèµ„æ–™å›ç­”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bf1f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rewrite(question):\n",
    "    \"\"\"\n",
    "    è®©æ¨¡å‹å¸®å¿™æŠŠå£è¯­åŒ–çš„é—®é¢˜æ”¹å†™æˆå…³é”®è¯\n",
    "    å‰¯ä½œç”¨ï¼šä¼šå¢åŠ 1-2ç§’çš„å»¶è¿Ÿï¼Œä½†æ£€ç´¢æ•ˆæœæ˜æ˜¾æå‡\n",
    "    \"\"\"\n",
    "    rewrite_prompt = f\"\"\"è¯·å°†ä¸‹é¢çš„é—®é¢˜æ”¹å†™ä¸ºæ›´é€‚åˆæ–‡æ¡£æ£€ç´¢çš„å…³é”®è¯æŸ¥è¯¢ã€‚\n",
    "è¦æ±‚ï¼š\n",
    "1. æå–æ ¸å¿ƒå…³é”®è¯\n",
    "2. å»é™¤å£è¯­åŒ–è¡¨è¾¾\n",
    "3. ä¿ç•™é‡è¦å®ä½“ï¼ˆäººåã€ç­çº§ã€æ—¶é—´ç­‰ï¼‰\n",
    "\n",
    "åŸé—®é¢˜: {question}\n",
    "\n",
    "æ”¹å†™åçš„æŸ¥è¯¢:\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": rewrite_prompt}\n",
    "    ]\n",
    "    \n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    generated_ids = model.generate(\n",
    "        model_inputs.input_ids,\n",
    "        max_new_tokens=50,\n",
    "        temperature=0.3,  # é™ä½æ¸©åº¦ï¼Œæ›´ç¡®å®šæ€§\n",
    "        do_sample=True\n",
    "    )\n",
    "    \n",
    "    generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)]\n",
    "    rewritten = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    return rewritten.strip()\n",
    "# è¯•è¯•çœ‹æ•ˆæœæ€ä¹ˆæ ·\n",
    "# æµ‹è¯•æŸ¥è¯¢æ”¹å†™\n",
    "original = \"é‚£ä¸ª23-3ç­çš„æ•°å­¦æœ€å‰å®³çš„åŒå­¦å«ä»€ä¹ˆåå­—æ¥ç€ï¼Ÿ\"\n",
    "rewritten = query_rewrite(original)\n",
    "\n",
    "print(f\"æ”¹å†™å: {rewritten}\")\n",
    "print(\"\\nçœ‹èµ·æ¥ç¡®å®ç®€æ´äº†å¾ˆå¤šï¼Œåº”è¯¥æ›´å®¹æ˜“åŒ¹é…åˆ°æ–‡æ¡£ï¼\")\n",
    "print(\"\\\\nâœ… æ”¹å†™åçš„æŸ¥è¯¢é€šå¸¸èƒ½æ›´ç²¾å‡†åœ°åŒ¹é…æ–‡æ¡£å†…å®¹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17df4358",
   "metadata": {},
   "source": [
    "### å®éªŒ2ï¼šæŸ¥è¯¢æ”¹å†™\n",
    "\n",
    "**é‡åˆ°çš„é—®é¢˜**ï¼šå‘ç°ç”¨æˆ·é—®çš„é—®é¢˜æ¯”è¾ƒå£è¯­åŒ–æ—¶ï¼ˆæ¯”å¦‚\"é‚£ä¸ª23-3ç­æ•°å­¦æœ€å‰å®³çš„åŒå­¦å«å•¥æ¥ç€ï¼Ÿ\"ï¼‰ï¼Œæ£€ç´¢æ•ˆæœä¸å¤ªå¥½ã€‚\n",
    "\n",
    "**æ”¹è¿›æƒ³æ³•**ï¼šèƒ½ä¸èƒ½è®©æ¨¡å‹å…ˆæŠŠé—®é¢˜\"ç¿»è¯‘\"æˆæ›´é€‚åˆæ£€ç´¢çš„å…³é”®è¯ï¼Ÿæ¯”å¦‚æå–å‡º\"23-3ç­\"ã€\"æ•°å­¦æœ€å¥½\"ã€\"å­¦ç”Ÿ\"è¿™äº›å…³é”®ä¿¡æ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218d4ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¹æ¯”ä¸€ä¸‹çº¯å‘é‡æ£€ç´¢å’Œæ··åˆæ£€ç´¢çš„æ•ˆæœ\n",
    "test_query = \"23-1ç­çš„å­¦ä¹ å§”å‘˜å­¦å·æ˜¯å¤šå°‘\"\n",
    "\n",
    "print(f\"æµ‹è¯•é—®é¢˜: '{test_query}'\\n\")\n",
    "\n",
    "print(\"========== çº¯å‘é‡æ£€ç´¢çš„ç»“æœ ==========\")\n",
    "vector_results = vectorstore.similarity_search_with_score(test_query, k=3)\n",
    "for i, (doc, score) in enumerate(vector_results[:3]):\n",
    "    print(f\"{i+1}. [åˆ†æ•°: {score:.4f}] {doc.page_content[:80]}...\")\n",
    "\n",
    "print(\"\\n========== æ··åˆæ£€ç´¢çš„ç»“æœ ==========\")\n",
    "hybrid_results = hybrid_retriever.retrieve(test_query, k=3, alpha=0.5)\n",
    "for i, (doc, score) in enumerate(hybrid_results):\n",
    "    print(f\"{i+1}. [åˆ†æ•°: {score:.4f}] {doc.page_content[:80]}...\")\n",
    "\n",
    "print(\"\\nè§‚å¯Ÿï¼šæ··åˆæ£€ç´¢ç¡®å®èƒ½æ›´å‡†ç¡®åœ°æ‰¾åˆ°åŒ…å«'å­¦å·'è¿™ç§å…³é”®è¯çš„æ–‡æ¡£ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07377173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# éœ€è¦å®‰è£… BM25 åº“ï¼ˆç”¨äºå…³é”®è¯æ£€ç´¢ï¼‰\n",
    "# !pip install rank-bm25\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "import jieba\n",
    "\n",
    "class HybridRetriever:\n",
    "    \"\"\"è‡ªå·±å®ç°çš„æ··åˆæ£€ç´¢å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self, vectorstore, chunks):\n",
    "        self.vectorstore = vectorstore\n",
    "        self.chunks = chunks\n",
    "        \n",
    "        # å…ˆæŠŠæ‰€æœ‰æ–‡æ¡£ç”¨jiebaåˆ†è¯ï¼Œæ„å»ºBM25ç´¢å¼•\n",
    "        print(\"æ­£åœ¨æ„å»º BM25 ç´¢å¼•...\")\n",
    "        tokenized_corpus = [list(jieba.cut(chunk.page_content)) for chunk in chunks]\n",
    "        self.bm25 = BM25Okapi(tokenized_corpus)\n",
    "        print(\"âœ… BM25 ç´¢å¼•æ„å»ºå®Œæˆ\")\n",
    "    \n",
    "    def retrieve(self, query, k=10, alpha=0.5):\n",
    "        \"\"\"\n",
    "        æ··åˆæ£€ç´¢çš„æ ¸å¿ƒé€»è¾‘\n",
    "        alpha: æƒé‡å‚æ•°ï¼Œ0.5è¡¨ç¤ºå„å 50%ï¼Œå¯ä»¥è°ƒæ•´è¯•è¯•æ•ˆæœ\n",
    "        \"\"\"\n",
    "        # ç¬¬ä¸€æ­¥ï¼šç”¨BM25åšå…³é”®è¯åŒ¹é…\n",
    "        tokenized_query = list(jieba.cut(query))\n",
    "        bm25_scores = self.bm25.get_scores(tokenized_query)\n",
    "        \n",
    "        # ç¬¬äºŒæ­¥ï¼šç”¨FAISSåšè¯­ä¹‰æ£€ç´¢\n",
    "        vector_results = self.vectorstore.similarity_search_with_score(query, k=k*2)\n",
    "        \n",
    "        # ç¬¬ä¸‰æ­¥ï¼šæŠŠä¸¤ä¸ªåˆ†æ•°å½’ä¸€åŒ–åˆ°0-1ä¹‹é—´\n",
    "        if max(bm25_scores) > 0:\n",
    "            bm25_scores = bm25_scores / max(bm25_scores)\n",
    "        \n",
    "        # å‘é‡ç›¸ä¼¼åº¦è½¬æ¢ï¼ˆFAISSè·ç¦»è¶Šå°è¶Šç›¸ä¼¼ï¼Œéœ€è¦è½¬æ¢ï¼‰\n",
    "        vector_scores = {}\n",
    "        max_distance = max([score for _, score in vector_results]) if vector_results else 1\n",
    "        for doc, score in vector_results:\n",
    "            idx = self.chunks.index(doc)\n",
    "            vector_scores[idx] = 1 - (score / max_distance if max_distance > 0 else 0)\n",
    "        \n",
    "        # 4. èåˆåˆ†æ•°\n",
    "        final_scores = {}\n",
    "        for idx in range(len(self.chunks)):\n",
    "            bm25_score = bm25_scores[idx]\n",
    "            vector_score = vector_scores.get(idx, 0)\n",
    "            final_scores[idx] = alpha * vector_score + (1 - alpha) * bm25_score\n",
    "        \n",
    "        # 5. æ’åºå¹¶è¿”å› top-k\n",
    "        top_indices = sorted(final_scores.keys(), key=lambda x: final_scores[x], reverse=True)[:k]\n",
    "        results = [(self.chunks[idx], final_scores[idx]) for idx in top_indices]\n",
    "        \n",
    "        return results\n",
    "\n",
    "# åˆ›å»ºæ··åˆæ£€ç´¢å™¨\n",
    "hybrid_retriever = HybridRetriever(vectorstore, chunks)\n",
    "print(\"âœ… æ··åˆæ£€ç´¢å™¨å·²åˆ›å»º\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864709fc",
   "metadata": {},
   "source": [
    "### å®éªŒ1ï¼šå°è¯•æ··åˆæ£€ç´¢\n",
    "\n",
    "**æƒ³æ³•**ï¼šçº¯å‘é‡æ£€ç´¢æœ‰æ—¶å€™ä¼šæ¼æ‰å…³é”®è¯ï¼Œæ¯”å¦‚æˆ‘é—®\"å­¦å·æ˜¯å¤šå°‘\"ï¼Œä½†æ–‡æ¡£é‡Œç›´æ¥å†™\"2023030173\"è¿™æ ·çš„æ•°å­—ã€‚å¦‚æœèƒ½ç»“åˆä¼ ç»Ÿçš„å…³é”®è¯æ£€ç´¢ï¼ˆBM25ï¼‰ï¼Œåº”è¯¥èƒ½æé«˜å‡†ç¡®ç‡ã€‚\n",
    "\n",
    "**å®ç°æ€è·¯**ï¼šæ£€ç´¢æ—¶åŒæ—¶ç”¨ BM25 å’Œå‘é‡æ£€ç´¢ï¼Œç„¶åæŠŠä¸¤ä¸ªåˆ†æ•°èåˆèµ·æ¥ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d76942",
   "metadata": {},
   "source": [
    "## ğŸ”§ RAG æ•ˆæœæ”¹è¿›å®éªŒè®°å½•\n",
    "\n",
    "### å‘ç°çš„é—®é¢˜\n",
    "åœ¨æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç°äº†ä¸€äº›é—®é¢˜ï¼š\n",
    "- æœ‰æ—¶å€™æ˜æ˜æ–‡æ¡£é‡Œæœ‰ä¿¡æ¯ï¼Œä½†æ˜¯æ£€ç´¢ä¸åˆ°ï¼ˆæ¯”å¦‚é—®\"å­¦å·\"ï¼Œä½†æ–‡æ¡£é‡Œå†™çš„æ˜¯æ‹¬å·é‡Œçš„æ•°å­—ï¼‰\n",
    "- é—®çš„é—®é¢˜æ¯”è¾ƒå£è¯­åŒ–æ—¶ï¼Œæ£€ç´¢æ•ˆæœä¸å¤ªå¥½\n",
    "- chunk_size=500 æœ‰æ—¶ä¼šæŠŠä¸€ä¸ªå®Œæ•´çš„ä¿¡æ¯åˆ‡æ–­\n",
    "- æ¨¡å‹æœ‰æ—¶å€™ä¼šèƒ¡è¯´å…«é“ï¼Œä¸è€å®æ‰¿è®¤\"ä¸çŸ¥é“\"\n",
    "\n",
    "### æ”¹è¿›æ€è·¯\n",
    "çœ‹äº†ä¸€äº›è®ºæ–‡å’Œèµ„æ–™åï¼Œå†³å®šå°è¯•è¿™äº›ä¼˜åŒ–ï¼š\n",
    "1. **æ··åˆæ£€ç´¢**ï¼šå•çº¯çš„è¯­ä¹‰æ£€ç´¢æœ‰æ—¶ä¸å¤Ÿç²¾ç¡®ï¼Œè¯•è¯•åŠ ä¸Šå…³é”®è¯åŒ¹é…ï¼ˆBM25ï¼‰\n",
    "2. **æŸ¥è¯¢æ”¹å†™**ï¼šæŠŠå£è¯­åŒ–çš„é—®é¢˜è½¬æˆå…³é”®è¯ï¼Œå¯èƒ½æ›´å®¹æ˜“åŒ¹é…åˆ°æ–‡æ¡£\n",
    "3. **æç¤ºè¯ä¼˜åŒ–**ï¼šç»™æ¨¡å‹æ›´æ˜ç¡®çš„æŒ‡ä»¤ï¼Œè®©å®ƒè€å®ç‚¹ï¼Œä¸çŸ¥é“å°±è¯´ä¸çŸ¥é“\n",
    "\n",
    "ä¸‹é¢è®°å½•ä¸€ä¸‹å®éªŒè¿‡ç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a1fa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é—®é¢˜: è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-1ç­çš„å­¦ä¹ å§”å‘˜æ˜¯è°ï¼Ÿ\n",
      "\n",
      "========== æ—  RAG å›ç­” ==========\n",
      "å¾ˆæŠ±æ­‰ï¼Œä½œä¸ºä¸€ä¸ªAIï¼Œæˆ‘æ— æ³•è·å–åˆ°å®æ—¶çš„ç­çº§ä¿¡æ¯æˆ–ç‰¹å®šç­çº§çš„å…·ä½“æˆå‘˜ä¿¡æ¯ï¼ŒåŒ…æ‹¬å­¦ä¹ å§”å‘˜æ˜¯è°ã€‚å»ºè®®ä½ ç›´æ¥å’¨è¯¢ä½ çš„è¾…å¯¼å‘˜æˆ–è€…ç­é•¿ç­‰æ¥è·å–å‡†ç¡®çš„ä¿¡æ¯ã€‚\n",
      "âš ï¸ æ¨¡å‹æ— æ³•å‡†ç¡®å›ç­”ï¼Œå› ä¸ºè®­ç»ƒæ•°æ®ä¸­ä¸åŒ…å«è¿™ä¸ªç§æœ‰ä¿¡æ¯\n",
      "\n",
      "========== æœ‰ RAG å›ç­” ==========\n",
      "å¾ˆæŠ±æ­‰ï¼Œä½œä¸ºä¸€ä¸ªAIï¼Œæˆ‘æ— æ³•è·å–åˆ°å®æ—¶çš„ç­çº§ä¿¡æ¯æˆ–ç‰¹å®šç­çº§çš„å…·ä½“æˆå‘˜ä¿¡æ¯ï¼ŒåŒ…æ‹¬å­¦ä¹ å§”å‘˜æ˜¯è°ã€‚å»ºè®®ä½ ç›´æ¥å’¨è¯¢ä½ çš„è¾…å¯¼å‘˜æˆ–è€…ç­é•¿ç­‰æ¥è·å–å‡†ç¡®çš„ä¿¡æ¯ã€‚\n",
      "âš ï¸ æ¨¡å‹æ— æ³•å‡†ç¡®å›ç­”ï¼Œå› ä¸ºè®­ç»ƒæ•°æ®ä¸­ä¸åŒ…å«è¿™ä¸ªç§æœ‰ä¿¡æ¯\n",
      "\n",
      "========== æœ‰ RAG å›ç­” ==========\n",
      "è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-1ç­çš„å­¦ä¹ å§”å‘˜æ˜¯ææ˜å®‡ï¼Œå­¦å·ä¸º2023217115ã€‚\n",
      "âœ… RAG ç³»ç»Ÿèƒ½å¤Ÿä»çŸ¥è¯†åº“ä¸­æ£€ç´¢åˆ°å‡†ç¡®ç­”æ¡ˆ\n",
      "\n",
      "========== å¯¹æ¯”åˆ†æ ==========\n",
      "âœ… RAG çš„ä¼˜åŠ¿: èƒ½å¤ŸåŸºäºç§æœ‰çŸ¥è¯†åº“å›ç­”é—®é¢˜ï¼Œè¿™äº›ä¿¡æ¯åœ¨å¤§æ¨¡å‹çš„è®­ç»ƒæ•°æ®ä¸­ä¸å­˜åœ¨\n",
      "âš ï¸ æ—  RAG: åªèƒ½ä¾èµ–è®­ç»ƒæ•°æ®ï¼Œæ— æ³•å›ç­”å…³äºç‰¹å®šç­çº§ã€å…¬å¸å†…éƒ¨ä¿¡æ¯ç­‰ç§æœ‰æ•°æ®çš„é—®é¢˜\n",
      "\n",
      "è¿™å°±æ˜¯ RAG çš„æ ¸å¿ƒä»·å€¼ï¼šè®©å¤§æ¨¡å‹èƒ½å¤Ÿè®¿é—®å’Œç†è§£ä½ çš„ç§æœ‰æ•°æ®ï¼\n",
      "è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-1ç­çš„å­¦ä¹ å§”å‘˜æ˜¯ææ˜å®‡ï¼Œå­¦å·ä¸º2023217115ã€‚\n",
      "âœ… RAG ç³»ç»Ÿèƒ½å¤Ÿä»çŸ¥è¯†åº“ä¸­æ£€ç´¢åˆ°å‡†ç¡®ç­”æ¡ˆ\n",
      "\n",
      "========== å¯¹æ¯”åˆ†æ ==========\n",
      "âœ… RAG çš„ä¼˜åŠ¿: èƒ½å¤ŸåŸºäºç§æœ‰çŸ¥è¯†åº“å›ç­”é—®é¢˜ï¼Œè¿™äº›ä¿¡æ¯åœ¨å¤§æ¨¡å‹çš„è®­ç»ƒæ•°æ®ä¸­ä¸å­˜åœ¨\n",
      "âš ï¸ æ—  RAG: åªèƒ½ä¾èµ–è®­ç»ƒæ•°æ®ï¼Œæ— æ³•å›ç­”å…³äºç‰¹å®šç­çº§ã€å…¬å¸å†…éƒ¨ä¿¡æ¯ç­‰ç§æœ‰æ•°æ®çš„é—®é¢˜\n",
      "\n",
      "è¿™å°±æ˜¯ RAG çš„æ ¸å¿ƒä»·å€¼ï¼šè®©å¤§æ¨¡å‹èƒ½å¤Ÿè®¿é—®å’Œç†è§£ä½ çš„ç§æœ‰æ•°æ®ï¼\n"
     ]
    }
   ],
   "source": [
    "def simple_chat(question):\n",
    "    \"\"\"ä¸ä½¿ç”¨ RAGï¼Œç›´æ¥é—®æ¨¡å‹\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "    \n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    generated_ids = model.generate(\n",
    "        model_inputs.input_ids,\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.7,\n",
    "        top_p=0.8,\n",
    "        do_sample=True\n",
    "    )\n",
    "    \n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] \n",
    "        for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    answer = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return answer\n",
    "\n",
    "# å¯¹æ¯”æµ‹è¯•ï¼šç§æœ‰æ•°æ®é—®é¢˜\n",
    "test_question = \"è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯23-1ç­çš„å­¦ä¹ å§”å‘˜æ˜¯è°ï¼Ÿ\"\n",
    "\n",
    "print(f\"é—®é¢˜: {test_question}\\n\")\n",
    "\n",
    "print(\"========== æ—  RAG å›ç­” ==========\")\n",
    "no_rag_answer = simple_chat(test_question)\n",
    "print(no_rag_answer)\n",
    "print(\"\\nâš ï¸ åˆ†æ: æ¨¡å‹æ— æ³•å‡†ç¡®å›ç­”ï¼Œå› ä¸ºè®­ç»ƒæ•°æ®ä¸­ä¸åŒ…å«è¿™ä¸ªç§æœ‰ä¿¡æ¯\")\n",
    "\n",
    "print(\"\\n========== æœ‰ RAG å›ç­” ==========\")\n",
    "rag_answer_text, _ = rag_answer(test_question)\n",
    "print(rag_answer_text)\n",
    "print(\"\\nâœ… åˆ†æ: RAG ç³»ç»Ÿèƒ½å¤Ÿä»çŸ¥è¯†åº“ä¸­æ£€ç´¢åˆ°å‡†ç¡®ç­”æ¡ˆ\")\n",
    "\n",
    "print(\"\\n========== å¯¹æ¯”åˆ†æ ==========\")\n",
    "print(\"âœ… RAG çš„ä¼˜åŠ¿: èƒ½å¤ŸåŸºäºç§æœ‰çŸ¥è¯†åº“å›ç­”é—®é¢˜ï¼Œè¿™äº›ä¿¡æ¯åœ¨å¤§æ¨¡å‹çš„è®­ç»ƒæ•°æ®ä¸­ä¸å­˜åœ¨\")\n",
    "print(\"âš ï¸ æ—  RAG: åªèƒ½ä¾èµ–è®­ç»ƒæ•°æ®ï¼Œæ— æ³•å›ç­”å…³äºç‰¹å®šç­çº§ã€å…¬å¸å†…éƒ¨ä¿¡æ¯ç­‰ç§æœ‰æ•°æ®çš„é—®é¢˜\")\n",
    "print(\"\\nè¿™å°±æ˜¯ RAG çš„æ ¸å¿ƒä»·å€¼ï¼šè®©å¤§æ¨¡å‹èƒ½å¤Ÿè®¿é—®å’Œç†è§£ä½ çš„ç§æœ‰æ•°æ®ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ad3e7f",
   "metadata": {},
   "source": [
    "## 10. æ€»ç»“\n",
    "\n",
    "### âœ… å·²å®Œæˆå†…å®¹\n",
    "æœ¬ Notebook å®Œæˆäº†å®Œæ•´çš„ RAG ç³»ç»Ÿæ„å»ºï¼š\n",
    "1. **çŸ¥è¯†åº“å¤„ç†**ï¼šåŠ è½½å¹¶å¤„ç† **7ä¸ªæ–‡æ¡£**\n",
    "   - 4ä¸ªè¯¾ç¨‹å…¬å¼€èµ„æ–™ï¼ˆå¤§çº²ã€FAQã€å®éªŒæŒ‡å¯¼ã€ä»£ç ç¤ºä¾‹ï¼‰\n",
    "   - 3ä¸ªç­çº§èŠ±åå†Œï¼ˆ23-1ç­48äººã€23-2ç­49äººã€23-3ç­50äººï¼‰\n",
    "2. **æ–‡æœ¬åˆ†å—**ï¼šä½¿ç”¨ RecursiveCharacterTextSplitterï¼Œchunk_size=500ï¼Œoverlap=50\n",
    "3. **å‘é‡åŒ–**ï¼šä½¿ç”¨ text2vec-base-chinese ä¸­æ–‡ä¼˜åŒ–æ¨¡å‹\n",
    "4. **FAISS ç´¢å¼•**ï¼šæ„å»ºå¹¶æŒä¹…åŒ–å‘é‡æ•°æ®åº“åˆ° `../vector_store`\n",
    "5. **ç›¸ä¼¼åº¦æ£€ç´¢**ï¼šå®ç° top-k æ£€ç´¢ï¼ŒéªŒè¯æ£€ç´¢è´¨é‡\n",
    "6. **RAG é—®ç­”**ï¼šé›†æˆ Qwen2.5-7B å®ç°å¢å¼ºç”Ÿæˆ\n",
    "7. **æ•ˆæœå¯¹æ¯”**ï¼šå±•ç¤º RAG vs æ™®é€šå¯¹è¯çš„å·®å¼‚\n",
    "8. **åŒåœºæ™¯éªŒè¯**ï¼šæ—¢èƒ½æŸ¥è¯¢è¯¾ç¨‹ä¿¡æ¯ï¼ˆå…¬å¼€èµ„æ–™ï¼‰ï¼Œä¹Ÿèƒ½æŸ¥è¯¢å­¦ç”Ÿä¿¡æ¯ï¼ˆç§æœ‰æ•°æ®ï¼‰\n",
    "\n",
    "### ğŸ¯ æ ¸å¿ƒä¼˜åŠ¿\n",
    "- **å‡†ç¡®æ€§æå‡**ï¼šåŸºäºçŸ¥è¯†åº“å›ç­”ï¼Œé¿å…æ¨¡å‹å¹»è§‰\n",
    "- **ç§æœ‰æ•°æ®æ”¯æŒ**ï¼šèƒ½å¤Ÿå›ç­”å…³äºç­çº§å­¦ç”Ÿä¿¡æ¯ç­‰ç§æœ‰æ•°æ®çš„é—®é¢˜ï¼ˆå¤§æ¨¡å‹è®­ç»ƒæ•°æ®ä¸­ä¸å­˜åœ¨ï¼‰\n",
    "- **å¯è¿½æº¯æ€§**ï¼šèƒ½å¤Ÿæ˜ç¡®å¼•ç”¨å‚è€ƒèµ„æ–™æ¥æº\n",
    "- **çµæ´»æ›´æ–°**ï¼šæ·»åŠ æ–°æ–‡æ¡£åé‡æ–°æ„å»ºç´¢å¼•å³å¯ï¼Œæ— éœ€é‡æ–°è®­ç»ƒæ¨¡å‹\n",
    "- **æˆæœ¬ä½å»‰**ï¼šåªéœ€å‘é‡åŒ–å’Œæ£€ç´¢ï¼Œæ— éœ€æ˜‚è´µçš„ GPU è®­ç»ƒ\n",
    "\n",
    "### ğŸ“Š æ€§èƒ½æŒ‡æ ‡\n",
    "- **å‘é‡åŒ–é€Ÿåº¦**ï¼šå–å†³äºæ–‡æ¡£æ•°é‡å’Œ Embedding æ¨¡å‹\n",
    "- **æ£€ç´¢å»¶è¿Ÿ**ï¼šFAISS æ£€ç´¢æ¯«ç§’çº§å“åº”\n",
    "- **ç”Ÿæˆå»¶è¿Ÿ**ï¼šçº¦ 3-4 ç§’ï¼ˆä¸æ¨¡å‹æ¨ç†æ—¶é—´ç›¸åŒï¼‰\n",
    "\n",
    "### ğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨\n",
    "1. **å¯åŠ¨ API æœåŠ¡**ï¼šè¿è¡Œ `python ../src/rag_server.py` å¯åŠ¨ RAG API\n",
    "2. **å‰ç«¯äº¤äº’**ï¼šæ‰“å¼€ `../web/rag_chat.html` è¿›è¡Œå¯è§†åŒ–å¯¹è¯\n",
    "3. **æ‰©å±•çŸ¥è¯†åº“**ï¼š\n",
    "   - å°†ä½ çš„æ–‡æ¡£ï¼ˆ.txtã€.mdã€.pdfç­‰ï¼‰æ·»åŠ åˆ° `../knowledge_base/`\n",
    "   - é‡æ–°è¿è¡Œæœ¬ Notebook çš„ç¬¬6-10ä¸ªcellæ„å»ºæ–°ç´¢å¼•\n",
    "4. **ä¼˜åŒ–æ£€ç´¢**ï¼š\n",
    "   - è°ƒæ•´ `chunk_size` å’Œ `chunk_overlap` å‚æ•°\n",
    "   - å°è¯•æ··åˆæ£€ç´¢ï¼ˆBM25 + å‘é‡æ£€ç´¢ï¼‰\n",
    "   - å®ç°é‡æ’åºï¼ˆRe-rankingï¼‰æå‡ç²¾åº¦\n",
    "\n",
    "### ğŸ“ RAG åº”ç”¨åœºæ™¯\n",
    "- **ä¼ä¸šçŸ¥è¯†åº“**ï¼šå†…éƒ¨æ–‡æ¡£ã€è§„ç« åˆ¶åº¦ã€æŠ€æœ¯æ‰‹å†Œ\n",
    "- **æ•™è‚²åœºæ™¯**ï¼šç­çº§ä¿¡æ¯ã€è¯¾ç¨‹èµ„æ–™ã€å­¦ç”Ÿæ¡£æ¡ˆï¼ˆå¦‚æœ¬ç¤ºä¾‹ï¼‰\n",
    "- **å®¢æˆ·æœåŠ¡**ï¼šäº§å“è¯´æ˜ä¹¦ã€FAQã€å†å²å·¥å•\n",
    "- **æ³•å¾‹åˆè§„**ï¼šæ³•è§„æ–‡ä»¶ã€åˆåŒæ¨¡æ¿ã€æ¡ˆä¾‹åˆ†æ\n",
    "- **åŒ»ç–—å¥åº·**ï¼šç—…å†è®°å½•ã€è¯Šç–—æŒ‡å—ã€è¯å“ä¿¡æ¯\n",
    "\n",
    "### ğŸ’¡ æ‰©å±•å»ºè®®\n",
    "- **å¤šæ¨¡æ€ RAG**ï¼šç»“åˆå›¾ç‰‡ã€è¡¨æ ¼ç­‰å¤šæ¨¡æ€å†…å®¹\n",
    "- **å¯¹è¯è®°å¿†**ï¼šä¿æŒå¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡\n",
    "- **åˆ†å¸ƒå¼éƒ¨ç½²**ï¼šä½¿ç”¨ Milvus æ›¿ä»£ FAISS å®ç°åˆ†å¸ƒå¼\n",
    "- **å®æ—¶æ›´æ–°**ï¼šç›‘å¬æ–‡æ¡£å˜åŒ–ï¼Œå¢é‡æ›´æ–°ç´¢å¼•\n",
    "- **æƒé™æ§åˆ¶**ï¼šä¸ºæ•æ„Ÿæ•°æ®æ·»åŠ è®¿é—®æƒé™ç®¡ç†"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm_deploy)",
   "language": "python",
   "name": "llm_deploy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
