# 人工智能原理课程 - 课程大纲

## 课程基本信息
- **课程名称**: 人工智能原理与应用
- **课程代码**: CS3301
- **学分**: 3.0
- **授课教师**: 刘雪南教授
- **先修课程**: 数据结构、概率论与数理统计、线性代数
- **适用专业**: 计算机科学与技术

---

## 课程目标

本课程旨在使学生：
1. 掌握人工智能的基本概念、原理与方法
2. 理解机器学习与深度学习的核心算法
3. 熟悉大语言模型（LLM）的基本原理与应用
4. 具备使用 Python 实现常见 AI 算法的能力
5. 了解 AI 技术在实际场景中的应用案例

---

## 教学内容与学时安排

### 第一章：人工智能概述（4学时）
- 1.1 人工智能的定义与发展历程
- 1.2 人工智能的主要流派与研究方向
- 1.3 人工智能的应用领域
- 1.4 伦理与社会影响

### 第二章：搜索与问题求解（6学时）
- 2.1 状态空间搜索
- 2.2 启发式搜索算法（A*, IDA*）
- 2.3 约束满足问题
- 2.4 博弈树与对抗搜索

### 第三章：机器学习基础（8学时）
- 3.1 监督学习：线性回归、逻辑回归
- 3.2 决策树与集成学习
- 3.3 支持向量机（SVM）
- 3.4 模型评估与交叉验证

### 第四章：神经网络与深度学习（10学时）
- 4.1 感知机与多层神经网络
- 4.2 反向传播算法
- 4.3 卷积神经网络（CNN）
- 4.4 循环神经网络（RNN & LSTM）
- 4.5 Transformer 架构

### 第五章：大语言模型（LLM）（8学时）
- 5.1 预训练语言模型原理
- 5.2 BERT、GPT 系列模型
- 5.3 提示工程（Prompt Engineering）
- 5.4 检索增强生成（RAG）
- 5.5 模型微调与对齐

### 第六章：强化学习（6学时）
- 6.1 马尔可夫决策过程（MDP）
- 6.2 Q-Learning 与 DQN
- 6.3 策略梯度方法
- 6.4 RLHF（人类反馈强化学习）

### 第七章：AI 应用实践（6学时）
- 7.1 计算机视觉应用
- 7.2 自然语言处理应用
- 7.3 推荐系统
- 7.4 AI 系统部署与优化

---

## 实验安排

### 实验 1：Python 与机器学习库入门（2学时）
- NumPy、Pandas、Matplotlib 基础
- Scikit-learn 库使用

### 实验 2：神经网络实现（4学时）
- 使用 PyTorch 构建 MLP
- 训练 MNIST 手写数字识别模型

### 实验 3：CNN 图像分类（4学时）
- 使用 ResNet 进行迁移学习
- CIFAR-10 数据集分类任务

### 实验 4：大语言模型应用（4学时）
- 使用 Hugging Face Transformers
- 文本生成与问答任务

### 实验 5：RAG 系统构建（4学时）
- 构建向量数据库
- 实现检索增强生成系统

---

## 考核方式

| 考核项目 | 占比 | 说明 |
|:---:|:---:|:---|
| **平时成绩** | 20% | 出勤、课堂表现、作业 |
| **实验成绩** | 30% | 5 次实验报告 |
| **课程设计** | 20% | 大模型部署与 RAG 实现 |
| **期末考试** | 30% | 闭卷考试 |

---

## 教材与参考资料

### 主教材
- 《人工智能：一种现代的方法》（第4版），Stuart Russell & Peter Norvig
- 《深度学习》，Ian Goodfellow 等著

### 参考资料
- 《动手学深度学习》，李沐等著
- 《Attention Is All You Need》，Transformer 原始论文
- Hugging Face 官方文档
- OpenAI GPT 系列技术报告

---

## 课程设计主题

**大模型本地化部署与 RAG 应用**

要求学生完成：
1. 选择开源大语言模型（如 Qwen、Llama 等）
2. 完成模型的本地部署
3. 基于 LangChain 构建 RAG 系统
4. 使用自定义知识库进行增强问答
5. 提供 API 接口与 Web 交互界面

详细要求请参见课程设计文档。

---

## 期末考试范围

### 重点章节
- 第三章：机器学习基础（监督学习算法）
- 第四章：神经网络与深度学习（Transformer）
- 第五章：大语言模型（预训练、微调、RAG）

### 题型分布
- 选择题（20分）：基本概念、算法原理
- 简答题（30分）：理论阐述、算法流程
- 计算题（20分）：反向传播、梯度计算
- 综合题（30分）：模型设计、应用场景分析

### 复习建议
1. 重点掌握神经网络的前向传播与反向传播
2. 理解 Transformer 的自注意力机制
3. 熟悉 RAG 的工作流程
4. 复习所有实验代码

---

**更新日期**: 2024年9月

**联系方式**: 如有问题请通过课程邮箱 ai_course@hfut.edu.cn 联系助教
